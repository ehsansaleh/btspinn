# An optional description of this config.
desc: Example Maxewll-Ampere equation applied to a closed rectangular current circuit.
# Date of the experimentation. This is optional and will not be used in training or summarization.
date: May 1, 2022

# The random number generator's list of seeds:
#   1. The range of values must be specified in a pythonic manner: [start, stop, step]
#   2. The number of models trained in parallel is determined by this option; this option
#      determines the number of completely independent models trained in parallel.
#   3. You can specify the list of seeds manually using the alternative `rng_seed/list` key.
rng_seed/range: [0, 100000, 1000]
# The type of problem. This is mainly used to make sure the correct script is running this config.
problem: maxwell
# The dimensionality of the problem
dim: 3

###################################################################################################
################################ The Optimization Hyper-parameters ################################
###################################################################################################
# The optimizer's type. Available options are 'adam' and 'sgd'.
opt/dstr: adam
# The optimizer's learning rate.
opt/lr: 0.001
# The number of optimization iterations. 
# This is the same as the number of `.step()` calls to the optimizer. 
opt/epoch: 200000

###################################################################################################
########################## Key Surface Point and Volume Sampling Options ##########################
###################################################################################################
# The number of training volumes (balls) in each training iteration. In other words, this 
# corresponds to the mini-batch size for the SGD optimizer.
vol/n: 400
# The number of surface points evaluated by the main model.
srfpts/n/mdl: 1
# The number of surface points evaluated by the target model.
srfpts/n/trg: 1
# Whether to use the double-sampling trick for constructing the training loss.
srfpts/dblsmpl: false
# Whether to deterministically space the sampled surface points or not.
srfpts/detspc: false
# Whether to use the delayed target method or not.
trg/btstrp: true
# The target weight in the delayed target method. 
# This determines the `M` hyper-parameter in Equation 5 of the main paper; The target weight is 
# essentially the same as $(M-1)/M$.
trg/w: 0.999
# The target smoothing factor in the delayed target method. 
# This corresponds to the $\tau$ hyper-parameter in Algorithm 1 of the main paper.
trg/tau/list: [0.6, 0.65, 0.7, 0.75, 0.8]
# The target regularization weight in the delayed target method. 
# This corresponds to the $\lambda$ hyper-parameter in Algorithm 1 of the main paper.
trg/reg/w/list: [16, 32, 64, 128]

###################################################################################################
########################### The Function Approximation Hyper-parameters ###########################
###################################################################################################
# The type of neural network. The only available option is `mlp`.
nn/dstr: mlp
# The width of the neural network; this is the number of neural units in each layer.
nn/width: 64
# The number of hidden layers in the neural network.
nn/hidden: 4
# The activation function of the network. The available values are `['silu', 'tanh', 'relu']`.
nn/act: tanh

###################################################################################################
################################ The Current Density Specifications ###############################
###################################################################################################
# This section defines the Maxwell-Ampere current density. Note that these are problem-defining 
# hyper-parameters, as opposed to optimization or solver-related hyper-parameters.

# The current density type. The only available option is `dmm` (i.e., "Delta Mixture Model").
wire/dstr: dmm
# The number of linear wire segments for the current density.
wire/n: 4
# The current density weight.
wire/w: [1.0]
# The source points of the current density; these points define the starting point of the current. 
# To define a closed circuit, the source of each segment should be placed on the sinking point of 
# the previous wire segment.
wire/src:
- [0.57735, -0.57735, -0.57735]
- [0.57735, 0.57735, 0.57735]
- [-0.57735, 0.57735, 0.57735]
- [-0.57735, -0.57735, -0.57735]
# The sinking points of the current density; these points define the ending point of the current. 
# To define a closed circuit, the source of each segment should be placed on the sinking point of 
# the previous wire segment.
wire/snk:
- [0.57735, 0.57735, 0.57735]
- [-0.57735, 0.57735, 0.57735]
- [-0.57735, -0.57735, -0.57735]
- [0.57735, -0.57735, -0.57735]

###################################################################################################
######################## The Training Integration Volume Hyper-Parameters #########################
###################################################################################################
# The type of the training volumes. The only available option is 'disk'.
vol/dstr: disk

# The training volume center distribution:
#   1. `ball` means that the training volume centers will be sampled in an IID and uniform manner 
#       within a ball.
#   2. `uniform` means the ball centers are sampled uniformly within a cube.
#   3. `normal` means the ball centers are sampled from a normal distribution.
vol/c/dstr: ball
# The hyper-center of the uniform ball used for uniformly sampling the training volume centers.
vol/c/c: [0.0]
# The hyper-radius of the uniform ball used for uniformly sampling the training volume centers.
vol/c/r: 1.0

# The training volume radius distribution:
#   1. `uniform` makes the radii themselves sampled uniformly from a 1-d interval.
#   2. `unifdpow` samples the radii such that their `d`-th power is distributed uniformly, where 
#      `d` is the problem space dimension.
vol/r/dstr: unifdpow
# The lower end of the sampled radii for the training volumes.
vol/r/low: 0.0
# The higher end of the sampled radii for the training volumes.
vol/r/high: 1.0
# The sampling distribution for the normal vector:
#   1. `uball` denotes sampling uniformly from the unit ball.
vol/nv/dstr: uball

###################################################################################################
############################## The Evaluation Distribution Profiles ###############################
###################################################################################################

###########################################################
####### The "Uniform Rectangle" Evaluation Profile ########
###########################################################
# The evaluation points distribution:
#   1. `uniform` dentoes sampling uniformly from a rectangle in an iid manner.
#   2. `ball` dentoes sampling uniformly from a ball in an iid manner.
#   3. `trnvol` dentoes sampling uniformly from within the training volumes.
#   4. `grid` dentoes sampling uniformly a rectangle in deterministic manner.
eval/ur/dstr: uniform
# The lower-left corner of the rectangle for sampling the evaluation points uniformly.
eval/ur/low: [-1.0]
# The top-right corner of the rectangle for sampling the evaluation points uniformly.
eval/ur/high: [1.0]
# The size of the evaluation points set.
eval/ur/n: 25000
# The frequency of evaluation in epochs.
eval/ur/frq: 1000

###########################################################
######### The "Uniform Ball 1" Evaluation Profile #########
###########################################################
# The evaluation points distribution:
#   1. `uniform` dentoes sampling uniformly from a rectangle in an iid manner.
#   2. `ball` dentoes sampling uniformly from a ball in an iid manner.
#   3. `trnvol` dentoes sampling uniformly from within the training volumes.
#   4. `grid` dentoes sampling uniformly a rectangle in deterministic manner.
eval/ub1/dstr: ball
# The center of the ball for sampling the evaluation points uniformly.
eval/ub1/c: [0.0]
# The radius of the ball for sampling the evaluation points uniformly.
eval/ub1/r: 1.0
# The size of the evaluation points set.
eval/ub1/n: 25000
# The frequency of evaluation in epochs.
eval/ub1/frq: 1000

###########################################################
######### The "Uniform Ball 2" Evaluation Profile #########
###########################################################

# The evaluation points distribution:
#   1. `uniform` dentoes sampling uniformly from a rectangle in an iid manner.
#   2. `ball` dentoes sampling uniformly from a ball in an iid manner.
#   3. `trnvol` dentoes sampling uniformly from within the training volumes.
#   4. `grid` dentoes sampling uniformly a rectangle in deterministic manner.
eval/ub2/dstr: ball
# The center of the ball for sampling the evaluation points uniformly.
eval/ub2/c: [0.0]
# The radius of the ball for sampling the evaluation points uniformly.
eval/ub2/r: sqrt(dim)
# The size of the evaluation points set.
eval/ub2/n: 25000
# The frequency of evaluation in epochs.
eval/ub2/frq: 1000

###########################################################
######### The "Uniform Grid 1" Evaluation Profile #########
###########################################################

# The evaluation points distribution:
#   1. `uniform` dentoes sampling uniformly from a rectangle in an iid manner.
#   2. `ball` dentoes sampling uniformly from a ball in an iid manner.
#   3. `trnvol` dentoes sampling uniformly from within the training volumes.
#   4. `grid` dentoes sampling uniformly a rectangle in deterministic manner.
eval/ug1/dstr: grid
# The lower-left corner of the rectangle for sampling the evaluation points uniformly.
eval/ug1/low: [-1.0, -1.0, -1.0]
# The top-right corner of the rectangle for sampling the evaluation points uniformly.
eval/ug1/high: [1.0, 1.0, 1.0]
# The size of the evaluation points set.
eval/ug1/n: [50, 50, 7]
# The frequency of evaluation in epochs.
eval/ug1/frq: 10000

###########################################################
######### The "Uniform Grid 2" Evaluation Profile #########
###########################################################

# The evaluation points distribution:
#   1. `uniform` dentoes sampling uniformly from a rectangle in an iid manner.
#   2. `ball` dentoes sampling uniformly from a ball in an iid manner.
#   3. `trnvol` dentoes sampling uniformly from within the training volumes.
#   4. `grid` dentoes sampling uniformly a rectangle in deterministic manner.
eval/ug2/dstr: grid
# The lower-left corner of the rectangle for sampling the evaluation points uniformly.
eval/ug2/low: [-1.0, -1.0, -1.0]
# The top-right corner of the rectangle for sampling the evaluation points uniformly.
eval/ug2/high: [1.0, 1.0, 1.0]
# The size of the evaluation points set.
eval/ug2/n: [200, 200, 7]
# The frequency of evaluation in epochs.
eval/ug2/frq: 40000

###########################################################
######## The "Training Volume" Evaluation Profile #########
###########################################################

# The evaluation points distribution:
#   1. `uniform` dentoes sampling uniformly from a rectangle in an iid manner.
#   2. `ball` dentoes sampling uniformly from a ball in an iid manner.
#   3. `trnvol` dentoes sampling uniformly from within the training volumes.
#   4. `grid` dentoes sampling uniformly a rectangle in deterministic manner.
eval/tv/dstr: trnvol
# The size of the evaluation points set.
eval/tv/n: 250000
# The frequency of evaluation in epochs.
eval/tv/frq: 1000

###################################################################################################
################################# The I/O Logistics and Settings ##################################
###################################################################################################
# The statistics averaging frequency. A value of 100 means that the training statistics are 
# averaged every 100 steps before being stored in the disk.
io/avg/frq: 100
# The model parameters checkpointing frequency. A value of 2500 means that a snapshot of the neural 
# models are stored every 2500 steps.
io/ckpt/frq: 2500
# The resource monitoring frequency. A value of 1000 means that a snapshot of the resource utilization  
# of the system (e.g., the CPU, RAM, GPU utilization) is evaluated and stored every 2500 steps.
io/mon/frq: 1000
# The floating point data type used in PyTorch. All floating point tensors and parameters (e.g., 
# the trained models) will be using this data type.
io/tch/dtype: float32
# The GZip compression level of the stored HDF files. 
io/cmprssn_lvl: 0
# The evaluation mini-batch size. This is different from the training mini-batch size, and it is 
# only used inside the evaluation protocol. Since the evaluation sample set may be larger than it 
# can fit the device memory, this mini-batch size will be used to split the evaluations into 
# manageable chunks. This setting should have no impact on the computed values. Since this option 
# can impact the performance of the algorithm, try and set it to the highest value that would not 
# result in an out of memory error. 
io/eval/bs: 256
# The flushing frequency of the collected results into the disk.
#   1. A value of 0 means that the entire results (e.g., the training and evaluation 
#      statistics and model checkpoints) are written once at the end of the training. 
#   2. A value of 100000 means that the the results are flushed every 100000 epochs to the disk.
io/flush/frq: 0

###################################################################################################
################################# The Looping Tree Specification ##################################
###################################################################################################
# This config file defines multiple training configurations, and the looping tree defines how 
# these configurations are derived from the provided values above.

# This specific file is defining a grid search for the delayed targe method hyper-parameters.

# The looping tree specification
looping/lines:
  - 'cart(aslist("rng_seed"),                                            '
  - '     "rest")                                                        '
