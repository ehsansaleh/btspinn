{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2315708d",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "This script only implements a Gaussian average gradient \n",
    "\n",
    "for performing latent parameter search (e.g., the location of the poisson charges) \n",
    "\n",
    "on the true problem oracle. \n",
    "\n",
    "In other words, no neural function approximation is performed in this script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e827df9",
   "metadata": {},
   "source": [
    "## The Poisson Problem Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d52d6d",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": [
     "active-ipynb"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "%matplotlib inline\n",
    "if importlib.util.find_spec(\"matplotlib_inline\") is not None:\n",
    "    import matplotlib_inline\n",
    "    matplotlib_inline.backend_inline.set_matplotlib_formats('retina')\n",
    "else:\n",
    "    from IPython.display import set_matplotlib_formats\n",
    "    set_matplotlib_formats('retina')\n",
    "\n",
    "plt.ioff();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import socket\n",
    "import random\n",
    "import pathlib\n",
    "import fnmatch\n",
    "import datetime\n",
    "import resource\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboardX\n",
    "import psutil\n",
    "import logging\n",
    "import torch.distributions\n",
    "from pyinstrument import Profiler\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from scipy.special import gamma\n",
    "from os.path import exists, isdir\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict as odict\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a370bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bspinn.io_utils import DataWriter\n",
    "from bspinn.io_utils import get_git_commit\n",
    "from bspinn.io_utils import preproc_cfgdict\n",
    "from bspinn.io_utils import hie2deep, deep2hie\n",
    "\n",
    "from bspinn.tch_utils import isscalar\n",
    "from bspinn.tch_utils import EMA\n",
    "from bspinn.tch_utils import BatchRNG\n",
    "from bspinn.tch_utils import bffnn\n",
    "from bspinn.tch_utils import profmem\n",
    "\n",
    "from bspinn.io_cfg import configs_dir\n",
    "from bspinn.io_cfg import results_dir\n",
    "from bspinn.io_cfg import storage_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429fa7a",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "Consider the $d$-dimensional space $\\mathbb{R}^{d}$, and the following charge:\n",
    "\n",
    "$$\\rho(x) = \\delta^d(x).$$\n",
    "\n",
    "For $d \\neq 2$, the analytical solution to the system\n",
    "\n",
    "$$\\nabla \\cdot \\vec{E} = \\rho$$\n",
    "\n",
    "$$\\nabla V = \\vec{E}$$\n",
    "\n",
    "can be defined as \n",
    "\n",
    "$$V_{\\vec{x}} = \\frac{\\Gamma(d/2)}{2\\cdot\\pi^{d/2}\\cdot (2-d)} \\|\\vec{x}\\|^{2-d}, $$\n",
    "\n",
    "$$\\vec{E}_{\\vec{x}} = \\frac{\\Gamma(d/2)}{2\\cdot \\pi^{d/2}\\cdot \\|\\vec{x}\\|^{d}} \\vec{x}.$$\n",
    "\n",
    "For $d=2$, $\\vec{E}_{\\vec{x}}$ is the same, but for $V_{\\vec{x}}$ we have\n",
    "\n",
    "$$V_{\\vec{x}} = \\frac{1}{2\\pi} \\ln(\\|\\vec{x}\\|).$$\n",
    "\n",
    "We want to solve this system using the divergence theorem:\n",
    "\n",
    "$$\\iint_{S_{d-1}(V)} \\vec{E}\\cdot \\hat{n}\\text{ d}S = \\iiint_{V_d} \\nabla.\\vec{E}\\text{ d}V.$$\n",
    "\n",
    "Keep in mind that the $d-1$-dimensional surface of a $d$-dimensional shpere with radius $r$ is \n",
    "$$\\iint_{S_{d-1}(V^{\\text{d-Ball}}_{r})} 1\\text{ d}S = \\frac{2\\cdot \\pi^{d/2}}{\\Gamma(d/2)}\\cdot r^{d-1}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c697fb22",
   "metadata": {},
   "source": [
    "### Dimensionality Scaling\n",
    "\n",
    "We will assume that our domain of solution is a d-Ball centerred at zero with a radius of $r_b$.\n",
    "$$C_1 := \\int_{V_{r_b}^{d\\text{-Ball}}} 1 d\\vec{x} = \\frac{2\\pi^{d/2}}{d\\cdot\\Gamma(d/2)} r_b^d$$\n",
    "\n",
    "#### The Expectation of the Anlytical Solution\n",
    "\n",
    "$$E_v := \\int_{V_r^{d\\text{-Ball}}} V_{\\vec{x}} d\\vec{x} = \\int \\frac{\\Gamma(d/2)}{2\\cdot\\pi^{d/2}\\cdot (2-d)} \\|\\vec{x}\\|^{2-d} d\\vec{x}$$\n",
    "\n",
    "$$ = C_1 \\cdot \\int \\frac{\\Gamma(d/2)}{2\\cdot\\pi^{d/2}\\cdot (2-d)} \\|\\vec{x}\\|^{2-d} \\cdot \\frac{1}{C_1} d\\vec{x} $$\n",
    "\n",
    "$$ = C_1 \\cdot \\frac{\\Gamma(d/2)}{2\\cdot\\pi^{d/2}\\cdot (2-d)} \\int \\|\\vec{x}\\|^{2-d} \\cdot \\frac{1}{C_1} d\\vec{x} $$\n",
    "\n",
    "$$ = \\frac{r_b^d}{d\\cdot(2-d)} \\cdot \\int \\|\\vec{x}\\|^{2-d} \\cdot \\frac{1}{C_1} d\\vec{x} $$\n",
    "\n",
    "$$ = \\frac{r_b^d}{d\\cdot(2-d)} \\cdot \\mathbb{E}_{\\vec{x}} [\\|\\vec{x}\\|^{2-d}] $$\n",
    "\n",
    "By defining the radius of $\\vec{x}$ as $r=\\|\\vec{x}\\|$, the distribution of $r$ is\n",
    "\n",
    "$$Pr(\\|\\vec{x}\\|<r) = (\\frac{r}{r_b})^d$$\n",
    "\n",
    "$$P(\\|\\vec{x}\\|=r) = \\frac{(d-1) \\cdot r^d}{r_b^d}$$\n",
    "\n",
    "Therefore, we have\n",
    "\n",
    "$$E_v = \\frac{r_b^d}{d\\cdot(2-d)} \\cdot \\mathbb{E}_{\\vec{x}} [r^{2-d}] $$\n",
    "\n",
    "$$ = \\frac{r_b^d}{d\\cdot(2-d)} \\cdot \\int_{r=0}^{r_b} r^{2-d} \\frac{(d-1) \\cdot r^d}{r_b^d} dr$$\n",
    "\n",
    "$$ = \\frac{r_b^d}{d\\cdot(2-d)} \\cdot \\frac{d}{r_b^d} \\int_{r=0}^{r_b} r dr$$\n",
    "\n",
    "$$ = \\frac{r_b^d}{d\\cdot(2-d)} \\cdot \\frac{d}{r_b^d} \\int_{r=0}^{r_b} r dr$$\n",
    "\n",
    "$$ = \\frac{r_b^2}{2\\cdot(2-d)}$$\n",
    "\n",
    "#### The Expectation of the Volume Ratio\n",
    "\n",
    "$$\\mathbb{E}_{r\\sim U[r_l, r_h]}[(\\frac{r}{r_b})^d] = \\frac{1}{r_h - r_l} \\int_{r_l}^{r_h} (\\frac{r}{r_b})^d dr$$\n",
    "\n",
    "$$=\\frac{1}{d+1} \\cdot \\frac{1}{r_b^d} \\frac{r_h^{d+1} - r_l^{d+1}}{r_h - r_l}.$$\n",
    "\n",
    "By setting $r_h=r_b$ and $r_l < r_h$, the above value closes in on $$\\frac{1}{d+1}$$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4bd0",
   "metadata": {},
   "source": [
    "### Defining the Problem and the Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfae0c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class DeltaProblem:\n",
    "    def __init__(self, weights, locations, tch_device, tch_dtype):\n",
    "        # weights          -> np.array -> shape=(n_bch, n_chrg)\n",
    "        # locations.shape  -> np.array -> shape=(n_bch, n_chrg, d)\n",
    "        self.weights = weights\n",
    "        self.locations = locations\n",
    "        self.n_bch, self.n_chrg = self.weights.shape\n",
    "        self.d = self.locations.shape[-1]\n",
    "        assert self.weights.shape == (self.n_bch, self.n_chrg,)\n",
    "        assert self.locations.shape == (self.n_bch, self.n_chrg, self.d)\n",
    "        self.weights_tch = torch.from_numpy(\n",
    "            self.weights).to(tch_device, tch_dtype)\n",
    "        self.locations_tch = torch.from_numpy(\n",
    "            self.locations).to(tch_device, tch_dtype)\n",
    "        self.shape = (self.n_bch,)\n",
    "        self.tch_pi = torch.tensor(np.pi, device=tch_device, dtype=tch_dtype)\n",
    "        self.ndim = 1\n",
    "\n",
    "    def integrate_volumes(self, volumes):\n",
    "        # volumes -> dictionary\n",
    "        assert volumes['type'] == 'ball'\n",
    "        centers = volumes['centers']\n",
    "        radii = volumes['radii']\n",
    "        n_v = radii.shape[-1]\n",
    "        n_bch, n_chrg, d = self.n_bch, self.n_chrg, self.d\n",
    "        assert radii.shape == (n_bch, n_v,)\n",
    "        assert centers.shape == (n_bch, n_v, d)\n",
    "        lib = torch if torch.is_tensor(centers) else np\n",
    "        mu = self.locations_tch if torch.is_tensor(centers) else self.locations\n",
    "        w = self.weights_tch if torch.is_tensor(centers) else self.weights\n",
    "\n",
    "        c_diff_mu = centers.reshape(\n",
    "            n_bch, n_v, 1, d) - mu.reshape(n_bch, 1, n_chrg, d)\n",
    "        assert c_diff_mu.shape == (n_bch, n_v, n_chrg, d)\n",
    "        distl2 = lib.sqrt(lib.square(c_diff_mu).sum(-1))\n",
    "        assert distl2.shape == (n_bch, n_v, n_chrg)\n",
    "        integ = ((distl2 < radii.reshape(n_bch, n_v, 1))\n",
    "                 * w.reshape(n_bch, 1, n_chrg)).sum(-1)\n",
    "        assert integ.shape == (n_bch, n_v)\n",
    "        return integ\n",
    "\n",
    "    def potential(self, x):\n",
    "        lib = torch if torch.is_tensor(x) else np\n",
    "        lib_pi = self.tch_pi if torch.is_tensor(x) else np.pi\n",
    "        w = self.weights_tch if torch.is_tensor(x) else self.weights\n",
    "        mu = self.locations_tch if torch.is_tensor(x) else self.locations\n",
    "        n_bch, n_chrg, d = self.n_bch, self.n_chrg, self.d\n",
    "        n_x = x.shape[-2]\n",
    "        assert x.shape == (\n",
    "            n_bch, n_x, d), f'x.shape={x.shape}, (n_bch, n_x, d)={(n_bch, n_x, d)}'\n",
    "        x_diff_mu = x.reshape(n_bch, n_x, 1, d) - \\\n",
    "            mu.reshape(self.n_bch, 1, n_chrg, d)\n",
    "        assert x_diff_mu.shape == (n_bch, n_x, n_chrg, d)\n",
    "        x_dists = lib.sqrt(lib.square(x_diff_mu).sum(-1))\n",
    "        assert x_dists.shape == (n_bch, n_x, n_chrg)\n",
    "        if d != 2:\n",
    "            poten1 = (x_dists**(2-d))\n",
    "            assert poten1.shape == (n_bch, n_x, n_chrg)\n",
    "            poten2 = (poten1 * w.reshape(n_bch, 1, n_chrg)).sum(-1)\n",
    "            assert poten2.shape == (n_bch, n_x)\n",
    "            cst = gamma(d/2) / (2*(lib_pi**(d/2)))\n",
    "            cst = cst / (2-d)\n",
    "            assert isscalar(cst)\n",
    "            poten = cst * poten2\n",
    "            assert poten.shape == (n_bch, n_x)\n",
    "        else:\n",
    "            poten1 = lib.log(x_dists)\n",
    "            assert poten1.shape == (n_bch, n_x, n_chrg)\n",
    "            poten2 = (poten1 * w.reshape(n_bch, 1, n_chrg)).sum(-1)\n",
    "            assert poten2.shape == (n_bch, n_x)\n",
    "            poten = poten2 / (2*lib_pi)\n",
    "            assert poten.shape == (n_bch, n_x)\n",
    "        return poten\n",
    "\n",
    "    def field(self, x):\n",
    "        lib = torch if torch.is_tensor(x) else np\n",
    "        lib_pi = self.tch_pi if torch.is_tensor(x) else np.pi\n",
    "        w = self.weights_tch if torch.is_tensor(x) else self.weights\n",
    "        mu = self.locations_tch if torch.is_tensor(x) else self.locations\n",
    "        n_bch, n_chrg, d = self.n_bch, self.n_chrg, self.d\n",
    "        n_x = x.shape[-2]\n",
    "        assert x.shape == (n_bch, n_x, d)\n",
    "        x_diff_mu = x.reshape(n_bch, n_x, 1, d) - \\\n",
    "            mu.reshape(n_bch, 1, n_chrg, d)\n",
    "        assert x_diff_mu.shape == (n_bch, n_x, n_chrg, d)\n",
    "        x_dists = lib.sqrt(lib.square(x_diff_mu).sum(-1))\n",
    "        assert x_dists.shape == (n_bch, n_x, n_chrg)\n",
    "        poten1 = (x_dists**(-d))\n",
    "        assert poten1.shape == (n_bch, n_x, n_chrg)\n",
    "        poten2 = (poten1 * w.reshape(n_bch, 1, n_chrg)).sum(-1)\n",
    "        assert poten2.shape == (n_bch, n_x)\n",
    "        cst = gamma(d/2) / (2*(lib_pi**(d/2)))\n",
    "        assert isscalar(cst)\n",
    "        poten = cst * poten2\n",
    "        assert poten.shape == (n_bch, n_x)\n",
    "        field = poten.reshape(n_bch, n_x, 1) * x\n",
    "        assert field.shape == (n_bch, n_x, d)\n",
    "        return field\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return dict(weights=self.weights_tch, locations=self.locations_tch)\n",
    "    \n",
    "    def load_state_dict(self, state_dict):\n",
    "        weights = state_dict['weights'].detach().cpu().numpy()\n",
    "        locations = state_dict['locations'].detach().cpu().numpy()\n",
    "        tch_device = self.weights_tch.device\n",
    "        tch_dtype = self.weights_tch.dtype\n",
    "        self.__init__(weights, locations, tch_device, tch_dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3319be1",
   "metadata": {},
   "source": [
    "### Defining the Volume Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e5270d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class BallSampler:\n",
    "    def __init__(self, c_dstr, c_params, r_dstr, r_params, batch_rng):\n",
    "        assert isinstance(c_params, dict)\n",
    "        for name, param in c_params.items():\n",
    "            msg_ = f'center param {name} is not np.array'\n",
    "            assert isinstance(param, np.ndarray), msg_\n",
    "        \n",
    "        assert isinstance(r_params, dict)\n",
    "        for name, param in r_params.items():\n",
    "            msg_ = f'radius param {name} is not np.array'\n",
    "            assert isinstance(param, np.ndarray), msg_\n",
    "\n",
    "        self.batch_rng = batch_rng\n",
    "        self.lib = batch_rng.lib\n",
    "        \n",
    "        ##############################################################\n",
    "        ################# Center Sampling Parameters #################\n",
    "        ##############################################################\n",
    "        c_params_ = c_params.copy()\n",
    "        self.c_dstr = c_dstr\n",
    "        if c_dstr == 'uniform':\n",
    "            c_low = c_params_.pop('low')\n",
    "            c_high = c_params_.pop('high')\n",
    "            \n",
    "            n_bch, dim = c_low.shape\n",
    "            \n",
    "            self.c_low_np = c_low.reshape(n_bch, 1, dim)\n",
    "            self.c_high_np = c_high.reshape(n_bch, 1, dim)\n",
    "            self.c_size_np = (self.c_high_np - self.c_low_np)\n",
    "\n",
    "            if self.lib == 'torch':\n",
    "                self.c_low_tch = torch.from_numpy(self.c_low_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "                self.c_high_tch = torch.from_numpy(self.c_high_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "                self.c_size_tch = torch.from_numpy(self.c_size_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "            \n",
    "            self.c_low = self.c_low_np if self.lib == 'numpy' else self.c_low_tch\n",
    "            self.c_size = self.c_size_np if self.lib == 'numpy' else self.c_size_tch\n",
    "        elif c_dstr == 'normal':\n",
    "            c_loc = c_params_.pop('loc')\n",
    "            c_scale = c_params_.pop('scale')\n",
    "            \n",
    "            n_bch, dim = c_loc.shape\n",
    "            self.c_loc_np = c_loc.reshape(n_bch, 1, dim)\n",
    "            self.c_scale_np = c_scale.reshape(n_bch, 1, 1)\n",
    "            \n",
    "            if self.lib == 'torch':\n",
    "                self.c_loc_tch = torch.from_numpy(self.c_loc_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "                self.c_scale_tch = torch.from_numpy(self.c_scale_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "                \n",
    "            self.c_loc = self.c_loc_np if self.lib == 'numpy' else self.c_loc_tch\n",
    "            self.c_scale = self.c_scale_np if self.lib == 'numpy' else self.c_scale_tch\n",
    "        elif c_dstr == 'ball':\n",
    "            c_cntr = c_params_.pop('c')\n",
    "            c_radi = c_params_.pop('r')\n",
    "            \n",
    "            n_bch, dim = c_cntr.shape\n",
    "            self.c_cntr_np = c_cntr.reshape(n_bch, 1, dim)\n",
    "            self.c_radi_np = c_radi.reshape(n_bch, 1, 1)\n",
    "            \n",
    "            if self.lib == 'torch':\n",
    "                self.c_cntr_tch = torch.from_numpy(self.c_cntr_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "                self.c_radi_tch = torch.from_numpy(self.c_radi_np).to(\n",
    "                    device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "                \n",
    "            self.c_cntr = self.c_cntr_np if self.lib == 'numpy' else self.c_cntr_tch\n",
    "            self.c_radi = self.c_radi_np if self.lib == 'numpy' else self.c_radi_tch\n",
    "        else:\n",
    "            raise ValueError(f'c_dstr=\"{c_dstr}\" not implemented')\n",
    "        \n",
    "        msg_ = f'Some center parameters were left unused: {list(c_params_.keys())}'\n",
    "        assert len(c_params_) == 0, msg_\n",
    "            \n",
    "        self.n_bch, self.d = n_bch, dim\n",
    "        \n",
    "        ##############################################################\n",
    "        ################# Radius Sampling Parameters #################\n",
    "        ##############################################################\n",
    "        r_params_ = r_params.copy()\n",
    "        r_low = r_params_.pop('low')\n",
    "        r_high = r_params_.pop('high')\n",
    "        \n",
    "        if r_dstr == 'uniform':\n",
    "            self.r_upow = 1.0\n",
    "        elif r_dstr == 'unifdpow':\n",
    "            self.r_upow = 1.0 / self.d\n",
    "        else:\n",
    "            raise ValueError(f'r_dstr={r_dstr} not implemented')\n",
    "\n",
    "        r_low_rshp = r_low.reshape(self.n_bch, 1)\n",
    "        r_high_rshp = r_high.reshape(self.n_bch, 1)\n",
    "        assert (r_low >= 0.0).all()\n",
    "        assert (r_high >= r_low).all()\n",
    "        \n",
    "        self.r_dstr = r_dstr\n",
    "        self.r_low_np = np.power(r_low_rshp, 1.0/self.r_upow)\n",
    "        self.r_high_np = np.power(r_high_rshp, 1.0/self.r_upow)\n",
    "        self.r_size_np = (self.r_high_np - self.r_low_np)\n",
    "        \n",
    "        if self.lib == 'torch':\n",
    "            self.r_low_tch = torch.from_numpy(self.r_low_np).to(\n",
    "                device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "            self.r_high_tch = torch.from_numpy(self.r_high_np).to(\n",
    "                device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "            self.r_size_tch = torch.from_numpy(self.r_size_np).to(\n",
    "                device=self.batch_rng.device, dtype=self.batch_rng.dtype)\n",
    "            \n",
    "        self.r_low = self.r_low_np if self.lib == 'numpy' else self.r_low_tch\n",
    "        self.r_size = self.r_size_np if self.lib == 'numpy' else self.r_size_tch\n",
    "        \n",
    "        msg_ = f'Some center parameters were left unused: {list(r_params_.keys())}'\n",
    "        assert len(r_params_) == 0, msg_\n",
    "\n",
    "    def __call__(self, n=1):\n",
    "        radii = self.r_low + self.r_size * \\\n",
    "            self.batch_rng.uniform((self.n_bch, n))\n",
    "        radii = radii ** self.r_upow\n",
    "        \n",
    "        if self.c_dstr == 'uniform':\n",
    "            centers = self.batch_rng.uniform((self.n_bch, n, self.d))\n",
    "            centers = centers * self.c_size + self.c_low\n",
    "        elif self.c_dstr == 'normal':\n",
    "            centers = self.batch_rng.normal((self.n_bch, n, self.d))\n",
    "            centers = centers * self.c_scale + self.c_loc\n",
    "        elif self.c_dstr == 'ball':\n",
    "            rnd1 = self.batch_rng.normal((self.n_bch, n, self.d))\n",
    "            rnd1 = rnd1 / ((rnd1**2).sum(-1, keepdims=True)**0.5)\n",
    "            \n",
    "            rnd2 = self.batch_rng.uniform((self.n_bch, n, 1))\n",
    "            rnd2 = rnd2 ** (1./self.d)\n",
    "            \n",
    "            centers = self.c_radi * rnd2 * rnd1 + self.c_cntr\n",
    "        else:\n",
    "            raise ValueError(f'c_dstr=\"{self.c_dstr}\" not implemented')\n",
    "        \n",
    "        d = dict()\n",
    "        d['type'] = 'ball'\n",
    "        d['centers'] = centers\n",
    "        d['radii'] = radii\n",
    "        return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b6294",
   "metadata": {},
   "source": [
    "### Sruface Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d890c38",
   "metadata": {
    "code_folding": [
     0,
     1,
     6,
     12,
     20
    ]
   },
   "outputs": [],
   "source": [
    "class SphereSampler:\n",
    "    def __init__(self, batch_rng):\n",
    "        self.tch_dtype = batch_rng.dtype\n",
    "        self.tch_device = batch_rng.device\n",
    "        self.batch_rng = batch_rng\n",
    "\n",
    "    def np_exlinspace(self, start, end, n):\n",
    "        assert n >= 1\n",
    "        a = np.linspace(start, end, n, endpoint=False)\n",
    "        b = a + 0.5 * (end - a[-1])\n",
    "        return b\n",
    "\n",
    "    def tch_exlinspace(self, start, end, n):\n",
    "        assert n >= 1\n",
    "        a = torch.linspace(start, end, n+1,\n",
    "                           device=self.tch_device,\n",
    "                           dtype=self.tch_dtype)[:-1]\n",
    "        b = a + 0.5 * (end - a[-1])\n",
    "        return b\n",
    "\n",
    "    def __call__(self, volumes, n, do_detspacing=True):\n",
    "        # volumes -> dictionary\n",
    "        assert volumes['type'] == 'ball'\n",
    "        centers = volumes['centers']\n",
    "        radii = volumes['radii']\n",
    "        n_bch, n_v, d = centers.shape\n",
    "        use_np = not torch.is_tensor(centers)\n",
    "        assert centers.shape == (n_bch, n_v, d)\n",
    "        assert radii.shape == (n_bch, n_v)\n",
    "        assert not (use_np) or (self.batch_rng.lib == 'numpy')\n",
    "        assert use_np or (self.batch_rng.device == centers.device)\n",
    "        assert use_np or (self.batch_rng.dtype == centers.dtype)\n",
    "        assert self.batch_rng.shape == (n_bch,)\n",
    "        exlinspace = self.np_exlinspace if use_np else self.tch_exlinspace\n",
    "        meshgrid = np.meshgrid if use_np else torch.meshgrid\n",
    "        sin = np.sin if use_np else torch.sin\n",
    "        cos = np.cos if use_np else torch.cos\n",
    "        matmul = np.matmul if use_np else torch.matmul\n",
    "\n",
    "        if do_detspacing and (d == 2):\n",
    "            theta = exlinspace(0.0, 2*np.pi, n)\n",
    "            assert theta.shape == (n,)\n",
    "            theta_2d = theta.reshape(n, 1)\n",
    "            x_tilde_2d_list = [cos(theta_2d), sin(theta_2d)]\n",
    "            if use_np:\n",
    "                x_tilde_2d = np.concatenate(x_tilde_2d_list, axis=1)\n",
    "            else:\n",
    "                x_tilde_2d = torch.cat(x_tilde_2d_list, dim=1)\n",
    "            assert x_tilde_2d.shape == (n, d)\n",
    "            x_tilde_4d = x_tilde_2d.reshape(1, 1, n, d)\n",
    "            assert x_tilde_4d.shape == (1, 1, n, d)\n",
    "            x_tilde = x_tilde_4d.expand(n_bch, 1, n, d)\n",
    "            assert x_tilde.shape == (n_bch, 1, n, d)\n",
    "        elif do_detspacing and (d == 3):\n",
    "            n_sqrt = int(np.sqrt(n))\n",
    "            assert n == n_sqrt * n_sqrt, 'Need n to be int-square for now!'\n",
    "            theta_1d = exlinspace(0.0, 2*np.pi, n_sqrt)\n",
    "            unit_unif = exlinspace(0.0, 1.0, n_sqrt)\n",
    "            if use_np:\n",
    "                phi_1d = np.arccos(1-2*unit_unif)\n",
    "            else:\n",
    "                phi_1d = torch.arccos(1-2*unit_unif)\n",
    "            theta_msh, phi_msh = meshgrid(theta_1d, phi_1d)\n",
    "            assert theta_msh.shape == (n_sqrt, n_sqrt)\n",
    "            assert phi_msh.shape == (n_sqrt, n_sqrt)\n",
    "            theta_2d, phi_2d = theta_msh.reshape(n, 1), phi_msh.reshape(n, 1)\n",
    "            assert theta_2d.shape == (n, 1)\n",
    "            assert phi_2d.shape == (n, 1)\n",
    "            x_tilde_lst = [sin(phi_2d) * cos(theta),\n",
    "                           sin(phi_2d) * sin(theta), cos(phi_2d)]\n",
    "            if use_np:\n",
    "                x_tilde_2d = np.concatenate(x_tilde_lst, axis=1)\n",
    "            else:\n",
    "                x_tilde_2d = torch.cat(x_tilde_lst, dim=1)\n",
    "            assert x_tilde_2d.shape == (n, d)\n",
    "            x_tilde_4d = x_tilde_2d.reshape(1, 1, n, d)\n",
    "            assert x_tilde_4d.shape == (1, 1, n, d)\n",
    "            x_tilde = x_tilde_4d.expand(n_bch, 1, n, d)\n",
    "            assert x_tilde.shape == (n_bch, 1, n, d)\n",
    "        elif (not do_detspacing) and (not use_np):\n",
    "            x_tilde_unnorm = self.batch_rng.normal((n_bch, n_v, n, d))\n",
    "            x_tilde_l2 = torch.sqrt(torch.square(x_tilde_unnorm).sum(dim=-1))\n",
    "            x_tilde = x_tilde_unnorm / x_tilde_l2.reshape(n_bch, n_v, n, 1)\n",
    "            assert x_tilde.shape == (n_bch, n_v, n, d)\n",
    "        else:\n",
    "            raise RuntimeError('Not implemented yet!')\n",
    "\n",
    "        if do_detspacing:\n",
    "            rot_mats = self.batch_rng.so_n((n_bch, n_v, d, d))\n",
    "            assert rot_mats.shape == (n_bch, n_v, d, d)\n",
    "\n",
    "        if do_detspacing:\n",
    "            x_tilde_rot = matmul(x_tilde, rot_mats)\n",
    "        else:\n",
    "            x_tilde_rot = x_tilde\n",
    "        assert x_tilde_rot.shape == (n_bch, n_v, n, d)\n",
    "\n",
    "        points = x_tilde_rot * \\\n",
    "            radii.reshape(n_bch, n_v, 1, 1) + centers.reshape(n_bch, n_v, 1, d)\n",
    "        assert points.shape == (n_bch, n_v, n, d)\n",
    "\n",
    "        if use_np:\n",
    "            x_tilde_bc = np.broadcast_to(x_tilde, (n_bch, n_v, n, d))\n",
    "        else:\n",
    "            x_tilde_bc = x_tilde.expand(n_bch, n_v, n, d)\n",
    "\n",
    "        if do_detspacing:\n",
    "            rot_x_tilde = matmul(x_tilde_bc, rot_mats)\n",
    "        else:\n",
    "            rot_x_tilde = x_tilde_bc\n",
    "        assert rot_x_tilde.shape == (n_bch, n_v, n, d)\n",
    "\n",
    "        cst = (2*(np.pi**(d/2))) / gamma(d/2)\n",
    "        csts = cst * (radii**(d-1))\n",
    "        assert csts.shape == (n_bch, n_v)\n",
    "\n",
    "        ret_dict = dict(points=points, normals=rot_x_tilde, areas=csts)\n",
    "        return ret_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae26e3",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393f4d9",
   "metadata": {
    "code_folding": [
     0,
     80,
     157,
     240,
     289,
     422
    ]
   },
   "outputs": [],
   "source": [
    "def get_nn_sol(model, x, n_eval=None, get_field=True, \n",
    "    out_lib='numpy'):\n",
    "    \"\"\"\n",
    "    Gets a model and evaluates it minibatch-wise on the tensor x. \n",
    "    The minibatch size is capped at n_eval. The output will have the \n",
    "    predicted potentials and the vector fields at them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: (nn.module) the batched neural network.\n",
    "\n",
    "    x: (torch.tensor) the evaluation points. This array should be \n",
    "        >2-dimensional and have a shape of `(..., x_rows, x_cols)`.\n",
    "\n",
    "    n_eval: (int or None) the maximum mini-batch size. If None is \n",
    "        given, `x_rows` will be used as `n_eval`.\n",
    "        \n",
    "    out_lib: (str) determines the output tensor type. Should be either \n",
    "        'numpy' or 'torch'.\n",
    "    \n",
    "    Output Dictionary\n",
    "    ----------\n",
    "    v: (np.array or torch.tensor) the evaluated potentials \n",
    "        with a shape of `(*model.shape, x_rows)` where\n",
    "        model.shape is the batch dimensions of the model. \n",
    "\n",
    "    e: (np.array or torch.tensor) the evaluated vector fields \n",
    "        with a shape of `(*model.shape, x_rows, x_cols)` where\n",
    "        model.shape is the batch dimensions of the model.\n",
    "    \"\"\"\n",
    "    x_rows, x_cols = tuple(x.shape)[-2:]\n",
    "    x_bd_ = tuple(x.shape)[:-2]\n",
    "    x_bd = (1,) if len(x_bd_) == 0 else x_bd_\n",
    "    msg_ = f'Cannot have {x.shape} fed to {model.shape}'\n",
    "    assert len(x_bd) <= model.ndim, msg_\n",
    "    if len(x_bd) < model.ndim:\n",
    "        x_bd = tuple([1] * (model.ndim-len(x_b)) + list(x_bd))\n",
    "    assert all((a == b) or (a == 1) or (b == 1) \n",
    "               for a, b in zip(x_bd, model.shape)), msg_\n",
    "    n_eval = x_rows if n_eval is None else n_eval\n",
    "    if out_lib == 'numpy':\n",
    "        to_lib = lambda a: a.detach().cpu().numpy()\n",
    "        lib_cat = lambda al: np.concatenate(al, axis=1)\n",
    "        lpf = '_np'\n",
    "    elif out_lib == 'torch':\n",
    "        to_lib = lambda a: a\n",
    "        lib_cat = lambda al: torch.cat(al, dim=1)\n",
    "        lpf = ''\n",
    "    else:\n",
    "        raise ValueError(f'outlib={outlib} not defined.')\n",
    "\n",
    "    n_batches = int(np.ceil(x_rows / n_eval))\n",
    "    v_pred_list = []\n",
    "    e_pred_list = []\n",
    "    for i in range(n_batches):\n",
    "        x_i = x[..., (i*n_eval):((i+1)*n_eval), :]\n",
    "        xi_rows = x_i.shape[-2]\n",
    "        x_ii = x_i.reshape(*x_bd, xi_rows, x_cols)\n",
    "        x_iii = x_ii.expand(*model.shape, xi_rows, x_cols)\n",
    "        x_iiii = nn.Parameter(x_iii)\n",
    "        v_pred_i = model(x_iiii).squeeze(-1)\n",
    "        v_pred_ii = to_lib(v_pred_i.detach())\n",
    "        v_pred_list.append(v_pred_ii)\n",
    "        if get_field:\n",
    "            e_pred_i, = torch.autograd.grad(v_pred_i.sum(), [x_iiii],\n",
    "                grad_outputs=None, retain_graph=False, create_graph=False,\n",
    "                only_inputs=True, allow_unused=False).squeeze(-1).detach()\n",
    "            e_pred_ii = to_lib(e_pred_i)\n",
    "            e_pred_list.append(e_pred_ii)\n",
    "\n",
    "    v_pred = lib_cat(v_pred_list)\n",
    "    if get_field:\n",
    "        e_pred = lib_cat(e_pred_list)\n",
    "    else:\n",
    "        e_pred = None\n",
    "\n",
    "    outdict = {f'v{lpf}': v_pred, f'e{lpf}': e_pred}\n",
    "    return outdict\n",
    "\n",
    "\n",
    "def get_prob_sol(problem, x, n_eval=None, get_field=True, \n",
    "    out_lib='numpy'):\n",
    "    \"\"\"\n",
    "    Gets a problem and evaluates the analytical solution to its \n",
    "    potentials and vector fields minibatch-wise on the tensor x. \n",
    "    The minibatch size is capped at n_eval. The output will have the \n",
    "    predicted potentials and the vector fields at them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    problem: (object) the problem with both the `potential` and \n",
    "        `field` methods for analytical solution evaluation.\n",
    "\n",
    "    x: (torch.tensor) the evaluation points. This array should be \n",
    "        >2-dimensional and have a shape of `(..., x_rows, x_cols)`.\n",
    "\n",
    "    n_eval: (int or None) the maximum mini-batch size. If None is \n",
    "        given, `x_rows` will be used as `n_eval`.\n",
    "\n",
    "    Output Dictionary\n",
    "    ----------\n",
    "    v_np: (np.array) the evaluated potentials with a shape of\n",
    "        `(..., x_rows)`. \n",
    "\n",
    "    e_np: (np.array) the evaluated vector fields with a shape of\n",
    "        `(..., x_rows, x_cols)`.\n",
    "    \"\"\"\n",
    "\n",
    "    assert hasattr(problem, 'potential')\n",
    "    assert callable(problem.potential)\n",
    "    assert hasattr(problem, 'field')\n",
    "    assert callable(problem.field)\n",
    "\n",
    "    x_rows, x_cols = tuple(x.shape)[-2:]\n",
    "    x_bd_ = tuple(x.shape)[:-2]\n",
    "    x_bd = (1,) if len(x_bd_) == 0 else x_bd_\n",
    "    msg_ = f'Cannot have {x.shape} fed to {problem.shape}'\n",
    "    assert len(x_bd) <= problem.ndim, msg_\n",
    "    if len(x_bd) < problem.ndim:\n",
    "        x_bd = tuple([1] * (problem.ndim-len(x_b)) + list(x_bd))\n",
    "    assert all((a == b) or (a == 1) or (b == 1) \n",
    "               for a, b in zip(x_bd, problem.shape)), msg_\n",
    "    n_eval = x_rows if n_eval is None else n_eval\n",
    "    if out_lib == 'numpy':\n",
    "        to_lib = lambda a: a.detach().cpu().numpy()\n",
    "        lib_cat = lambda al: np.concatenate(al, axis=1)\n",
    "        lpf = '_np'\n",
    "    elif out_lib == 'torch':\n",
    "        to_lib = lambda a: a\n",
    "        lib_cat = lambda al: torch.cat(al, dim=1)\n",
    "        lpf = ''\n",
    "    else:\n",
    "        raise ValueError(f'outlib={outlib} not defined.')\n",
    "\n",
    "    n_batches = int(np.ceil(x_rows / n_eval))\n",
    "    v_list = []\n",
    "    e_list = []\n",
    "    for i in range(n_batches):\n",
    "        x_i = x[..., (i*n_eval):((i+1)*n_eval), :]\n",
    "        xi_rows = x_i.shape[-2]\n",
    "        x_ii = x_i.reshape(*x_bd, xi_rows, x_cols)\n",
    "        x_iii = x_ii.expand(*problem.shape, xi_rows, x_cols)\n",
    "        v_i = problem.potential(x_iii)\n",
    "        v_list.append(to_lib(v_i))\n",
    "        if get_field:\n",
    "            e_i = problem.field(x_iii)\n",
    "            e_list.append(to_lib(e_i))\n",
    "\n",
    "    v = lib_cat(v_list)\n",
    "    if get_field:\n",
    "        e = lib_cat(e_list)\n",
    "    else:\n",
    "        e = None\n",
    "    outdict = {f'v{lpf}': v, f'e{lpf}': e}\n",
    "    return outdict\n",
    "\n",
    "\n",
    "def make_grid(x_low, x_high, dim, n_gpd, lib):\n",
    "    \"\"\"\n",
    "    Creates a grid of points using the mesgrid functions\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_low: (list) a list of length `dim` with floats \n",
    "        representing the lower limits of the grid.\n",
    "    \n",
    "    x_high: (list) a list of length `dim` with floats \n",
    "        representing the higher limits of the grid.\n",
    "    \n",
    "    dim: (int) the dimension of the grid space.\n",
    "    \n",
    "    n_gpd: (int) the number of points in each \n",
    "        grid dimension. This yields a total of \n",
    "        `n_gpd**dim` points in the total grid.\n",
    "        \n",
    "    lib: (str) either 'torch' or 'numpy'. This determines \n",
    "        the type of `x` output.\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    x: (torch.tensor or np.array) a 2-d tensor or array \n",
    "        with the shape of `(n_gpd**dim, dim)`. \n",
    "    \n",
    "    xi_msh_np: (list of np.array) a list of length `dim` \n",
    "        with meshgrid tensors each with a shape of \n",
    "        `[n_gpd] * dim`.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert dim == 2, 'not implemented yet'\n",
    "    assert len(x_low) == dim\n",
    "    assert len(x_high) == dim\n",
    "    assert lib in ('torch', 'numpy')\n",
    "    library = torch if lib == 'torch' else np\n",
    "    tnper = lambda a: a.cpu().detach().numpy()\n",
    "    nper = tnper if lib == 'torch' else lambda a: a\n",
    "    \n",
    "    x1_low, x2_low = x_low\n",
    "    x1_high, x2_high = x_high\n",
    "    n_g_plt = n_gpd ** dim\n",
    "\n",
    "    x1_1d = library.linspace(x1_low, x1_high, n_gpd)\n",
    "    assert x1_1d.shape == (n_gpd,)\n",
    "\n",
    "    x2_1d = library.linspace(x2_low, x2_high, n_gpd)\n",
    "    assert x2_1d.shape == (n_gpd,)\n",
    "\n",
    "    x1_msh, x2_msh = library.meshgrid(x1_1d, x2_1d)\n",
    "    assert x1_msh.shape == (n_gpd, n_gpd)\n",
    "    assert x2_msh.shape == (n_gpd, n_gpd)\n",
    "\n",
    "    x1 = x1_msh.reshape(n_g_plt, 1)\n",
    "    assert x1.shape == (n_g_plt, 1)\n",
    "\n",
    "    x2 = x2_msh.reshape(n_g_plt, 1)\n",
    "    assert x2.shape == (n_g_plt, 1)\n",
    "\n",
    "    x1_1d_c = x1_1d.reshape(n_gpd, 1)\n",
    "    assert x1_1d_c.shape == (n_gpd, 1)\n",
    "\n",
    "    x2_1d_c = x2_1d.reshape(n_gpd, 1)\n",
    "    assert x2_1d_c.shape == (n_gpd, 1)\n",
    "\n",
    "    x1_msh_np = nper(x1_msh)\n",
    "    assert x1_msh_np.shape == (n_gpd, n_gpd)\n",
    "\n",
    "    x2_msh_np = nper(x2_msh)\n",
    "    assert x1_msh_np.shape == (n_gpd, n_gpd)\n",
    "\n",
    "    x = torch.cat([x1, x2], dim=1)\n",
    "    assert x.shape == (n_g_plt, dim)\n",
    "\n",
    "    x_np = nper(x)\n",
    "    assert x_np.shape == (n_g_plt, dim)\n",
    "    \n",
    "    xi_msh_np = [x1_msh_np, x2_msh_np]\n",
    "    outdict = dict(x=x, xi_msh_np=xi_msh_np)\n",
    "\n",
    "    return outdict\n",
    "\n",
    "\n",
    "def plot_sol(x1_msh_np, x2_msh_np, sol_dict, fig=None, ax=None, cax=None):\n",
    "    n_gpd, dim = x1_msh_np.shape[0], x1_msh_np.ndim\n",
    "    assert dim == 2, f'dim={dim}, x1_msh_np.shape={x1_msh_np.shape}'\n",
    "    assert x1_msh_np.shape == (n_gpd, n_gpd)\n",
    "    assert x2_msh_np.shape == (n_gpd, n_gpd)\n",
    "    n_g = (n_gpd ** dim)\n",
    "   \n",
    "    if fig is None:\n",
    "        assert ax is None\n",
    "        assert cax is None\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3.0, 2.5), dpi=72)\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "    else:\n",
    "        assert ax is not None\n",
    "   \n",
    "    e_percentile_cap = 90\n",
    "    \n",
    "    v_np = sol_dict['v_np']\n",
    "    assert v_np.shape[-1] == n_g\n",
    "    \n",
    "    v_msh_np = v_np.reshape(-1, n_gpd, n_gpd).mean(axis=0)\n",
    "    im = ax.pcolormesh(x1_msh_np, x2_msh_np, v_msh_np,\n",
    "                        shading='auto', cmap='RdBu')\n",
    "    if cax is not None:\n",
    "        fig.colorbar(im, cax=cax)\n",
    "\n",
    "    e_msh_np = sol_dict['e_np']\n",
    "    if e_msh_np is not None:\n",
    "        assert e_msh_np.shape[-2:] == (n_g, dim)\n",
    "        e_msh_np = e_msh_np.reshape(-1, n_gpd,\n",
    "            n_gpd, dim).mean(axis=0)\n",
    "        if e_percentile_cap is not None:\n",
    "            e_size = np.sqrt((e_msh_np**2).sum(axis=-1))\n",
    "            e_size_cap = np.percentile(a=e_size, \n",
    "                q=e_percentile_cap, axis=None)\n",
    "            cap_coef = np.ones_like(e_size)\n",
    "            cap_coef[e_size > e_size_cap] = e_size_cap / \\\n",
    "                e_size[e_size > e_size_cap]\n",
    "            e_msh_capped = e_msh_np * \\\n",
    "                cap_coef.reshape(*e_msh_np.shape[:-1], 1)\n",
    "        else:\n",
    "            e_msh_capped = e_msh_np\n",
    "\n",
    "        ax.quiver(x1_msh_np, x2_msh_np,\n",
    "            e_msh_capped[:, :, 0], e_msh_capped[:, :, 1])\n",
    "    return fig, ax, cax\n",
    "\n",
    "\n",
    "def get_perfdict(e_pnts, e_mdlsol, e_prbsol):\n",
    "    \"\"\"\n",
    "    Computes the biased, bias-corrected, and slope-corrected error \n",
    "    metrics for the solutions of a Poisson problem.\n",
    "    \n",
    "    This function computes three types of MSE and MAE statistics:\n",
    "        \n",
    "        1. Plain: just take the model and ground truth solution\n",
    "            and subtract them to get the errors. No bias- or slope-correction \n",
    "            is applied to offset those degrees of freedom.\n",
    "            \n",
    "            shorthand: 'pln'\n",
    "            \n",
    "        2. Bias-corrected: subtracts the average value from both the model \n",
    "            and ground truth solutions, and then computes the errors.\n",
    "            \n",
    "            shorthand: 'bc'\n",
    "            \n",
    "        3. Slope-corrected: Since any linear function can be added to the\n",
    "            Poisson solutions without violating the poisson equation, this\n",
    "            function fits an ordinary least squares to both the model and\n",
    "            ground truth solutions, and then subtracts it from them. This\n",
    "            way, even the arbitrary-slope issue can be addressed.\n",
    "            \n",
    "            shorthand: 'slc'\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "    e_pnts: (torch.tensor) The input points to the model and the ground truth.\n",
    "        This should have a shape of (n_seeds, n_evlpnts, dim).\n",
    "        \n",
    "    e_mdlsol: (torch.tensor) The model solution with a\n",
    "        (n_seeds, n_evlpnts) shape.\n",
    "    \n",
    "    e_prbsol: (torch.tensor) The ground truth solution with a\n",
    "        (n_seeds, n_evlpnts) shape.\n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    outdict: (dict) A mapping between the error keys and their numpy arrays.\n",
    "        The error keys are the cartesian product of ('pln', 'bc', 'slc') \n",
    "        and ('mse', 'mae').\n",
    "    \"\"\"\n",
    "    n_seeds, n_evlpnts, dim = e_pnts.shape\n",
    "    assert e_mdlsol.shape == (n_seeds, n_evlpnts)\n",
    "    assert e_prbsol.shape == (n_seeds, n_evlpnts)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # The plain non-processed error matrix\n",
    "        err_pln = e_mdlsol - e_prbsol\n",
    "        assert err_pln.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        # The bias-corrected error matrix\n",
    "        e_mdlsol2 = e_mdlsol - e_mdlsol.mean(dim=1, keepdims=True)\n",
    "        assert e_mdlsol2.shape == (n_seeds, n_evlpnts)\n",
    "        e_prbsol2 = e_prbsol - e_prbsol.mean(dim=1, keepdims=True)\n",
    "        assert e_prbsol2.shape == (n_seeds, n_evlpnts)\n",
    "        err_bc = e_mdlsol2 - e_prbsol2\n",
    "        assert err_bc.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        # The slope-corrected error matrix\n",
    "        e_pntstrans = e_pnts.transpose(-1, -2)\n",
    "        assert e_pntstrans.shape == (n_seeds, dim, n_evlpnts)\n",
    "        e_pntsig = e_pntstrans.matmul(e_pnts)\n",
    "        assert e_pntsig.shape == (n_seeds, dim, dim)\n",
    "        e_pntsiginv = torch.pinverse(e_pntsig)\n",
    "        assert e_pntsiginv.shape == (n_seeds, dim, dim)\n",
    "        e_pntpinv = e_pntsiginv.matmul(e_pntstrans)\n",
    "        assert e_pntpinv.shape == (n_seeds, dim, n_evlpnts)\n",
    "        \n",
    "        # e_pntpinv = torch.pinverse(e_pnts)\n",
    "        # assert e_pntpinv.shape == (n_seeds, dim, n_evlpnts)\n",
    "        \n",
    "        e_mdlbeta = e_pntpinv.matmul(e_mdlsol2.unsqueeze(-1))\n",
    "        assert e_mdlbeta.shape == (n_seeds, dim, 1)\n",
    "        e_mdlslpcrc = e_pnts.matmul(e_mdlbeta)\n",
    "        assert e_mdlslpcrc.shape == (n_seeds, n_evlpnts, 1)\n",
    "        e_mdlsol3 = e_mdlsol2 - e_mdlslpcrc.squeeze(-1)\n",
    "        assert e_mdlsol3.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        e_prbbeta = e_pntpinv.matmul(e_prbsol2.unsqueeze(-1))\n",
    "        assert e_prbbeta.shape == (n_seeds, dim, 1)\n",
    "        e_prbslpcrc = e_pnts.matmul(e_prbbeta)\n",
    "        assert e_prbslpcrc.shape == (n_seeds, n_evlpnts, 1)\n",
    "        e_prbsol3 = e_prbsol2 - e_prbslpcrc.squeeze(-1)\n",
    "        assert e_prbsol3.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        err_slc = e_mdlsol3 - e_prbsol3\n",
    "        assert err_slc.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        # The normalized slope-corrected error matrix\n",
    "        e_mdlsol4 = e_mdlsol3 / e_mdlsol3.std(dim=1, keepdim=True)\n",
    "        assert e_mdlsol4.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        e_prbsol4 = e_prbsol3 / e_prbsol3.std(dim=1, keepdim=True)\n",
    "        assert e_prbsol4.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        err_scn = e_mdlsol4 - e_prbsol4\n",
    "        assert err_scn.shape == (n_seeds, n_evlpnts)\n",
    "        \n",
    "        # Computing the mse and mae values\n",
    "        e_plnmse = err_pln.square().mean(dim=-1)\n",
    "        assert e_plnmse.shape == (n_seeds,)\n",
    "        e_plnmae = err_pln.abs().mean(dim=-1)\n",
    "        assert e_plnmse.shape == (n_seeds,)\n",
    "        \n",
    "        e_bcmse = err_bc.square().mean(dim=-1)\n",
    "        assert e_bcmse.shape == (n_seeds,)\n",
    "        e_bcmae = err_bc.abs().mean(dim=-1)\n",
    "        assert e_bcmse.shape == (n_seeds,)\n",
    "        \n",
    "        e_slcmse = err_slc.square().mean(dim=-1)\n",
    "        assert e_slcmse.shape == (n_seeds,)\n",
    "        e_slcmae = err_slc.abs().mean(dim=-1)\n",
    "        assert e_slcmse.shape == (n_seeds,)\n",
    "        \n",
    "        e_scnmse = err_scn.square().mean(dim=-1)\n",
    "        assert e_scnmse.shape == (n_seeds,)\n",
    "        e_scnmae = err_scn.abs().mean(dim=-1)\n",
    "        assert e_scnmse.shape == (n_seeds,)\n",
    "    \n",
    "        outdict = {'pln/mse': e_plnmse.detach().cpu().numpy(),\n",
    "                   'pln/mae': e_plnmae.detach().cpu().numpy(),\n",
    "                   'bc/mse': e_bcmse.detach().cpu().numpy(),\n",
    "                   'bc/mae': e_bcmae.detach().cpu().numpy(),\n",
    "                   'slc/mse': e_slcmse.detach().cpu().numpy(),\n",
    "                   'slc/mae': e_slcmae.detach().cpu().numpy(),\n",
    "                   'scn/mse': e_scnmse.detach().cpu().numpy(),\n",
    "                   'scn/mae': e_scnmae.detach().cpu().numpy()}\n",
    "    \n",
    "    return outdict\n",
    "\n",
    "\n",
    "def eval_pnts(problem, model, target, e_pnts, do_bootstrap,\n",
    "    n_seeds, n_evlpnts, dim, eval_bs):\n",
    "    assert e_pnts.shape == (n_seeds, n_evlpnts, dim)\n",
    "\n",
    "    # Computing the model, target and ground truth solutions\n",
    "    e_prbsol = get_prob_sol(problem, e_pnts, n_eval=eval_bs, \n",
    "        get_field=False, out_lib='torch')['v']\n",
    "    assert e_prbsol.shape == (n_seeds, n_evlpnts)\n",
    "\n",
    "    # Computing the model solution\n",
    "    with torch.no_grad():\n",
    "        e_mdlsol = get_nn_sol(model, e_pnts, n_eval=eval_bs,\n",
    "            get_field=False, out_lib='torch')['v']\n",
    "        assert e_mdlsol.shape == (n_seeds, n_evlpnts)\n",
    "\n",
    "    # Computing the target solution\n",
    "    if do_bootstrap:\n",
    "        with torch.no_grad():\n",
    "            e_trgsol = get_nn_sol(target, e_pnts, n_eval=eval_bs, \n",
    "                get_field=False, out_lib='torch')['v']\n",
    "        assert e_trgsol.shape == (n_seeds, n_evlpnts)\n",
    "\n",
    "    eperfs = dict()\n",
    "    eperfs['mdl'] = get_perfdict(e_pnts, e_mdlsol, e_prbsol)\n",
    "    if do_bootstrap:\n",
    "        eperfs['trg'] = get_perfdict(e_pnts, e_trgsol, e_prbsol)\n",
    "    eperfs = deep2hie(eperfs, dictcls=dict)\n",
    "    # Example: eperfs = {'mdl/pln/mse': ...,\n",
    "    #                    'mdl/pln/mae': ...,\n",
    "    #                    'mdl/bc/mse': ...,\n",
    "    #                    'mdl/bc/mae': ...,\n",
    "    #                    'mdl/slc/mse': ...,\n",
    "    #                    'mdl/slc/mae': ...,\n",
    "    #                    'trg/pln/mse': ...,\n",
    "    #                    'trg/pln/mae': ...,\n",
    "    #                    'trg/bc/mse': ...,\n",
    "    #                    'trg/bc/mae': ...,\n",
    "    #                    'trg/slc/mse': ...,\n",
    "    #                    'trg/slc/mae': ...,\n",
    "    #                   }\n",
    "    return eperfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fa95d5",
   "metadata": {},
   "source": [
    "## Utility Functions for Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f525f",
   "metadata": {
    "code_folding": [
     8,
     60,
     85
    ]
   },
   "outputs": [],
   "source": [
    "#########################################################\n",
    "########### Sanity Checking Utility Functions ###########\n",
    "#########################################################\n",
    "\n",
    "msg_bcast = '{} should be np broadcastable to {}={}. '\n",
    "msg_bcast += 'However, it has an inferred shape of {}.'\n",
    "\n",
    "\n",
    "def get_arr(name, trgshp_str, trns_opts):\n",
    "    \"\"\"\n",
    "    Gets a list of values, and checks if it is broadcastable to a \n",
    "    target shape. If the shape does not match, it will raise a proper\n",
    "    assertion error with a meaninful message. The output is a numpy \n",
    "    array that is guaranteed to be broadcastable to the target shape.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name: (str) name of the option / hyper-parameter.\n",
    "\n",
    "    trgshp_str: (str) the target shape elements representation. Must be a \n",
    "        valid python expression where the needed elements .\n",
    "\n",
    "    trns_opts: (dict) a dictionary containing the variables needed \n",
    "        for the string to list translation of val.\n",
    "\n",
    "    Key Variables\n",
    "    -------------\n",
    "    `val = trns_opts[name]`: (list or str) list of values read \n",
    "        from the config file. If a string is provided, python's \n",
    "        `eval` function will be used to translate it into a list.\n",
    "        \n",
    "    `trg_shape = eval_formula(trgshp_str, trns_opts)`: (tuple) \n",
    "        the target shape.\n",
    "    \n",
    "    Output\n",
    "    ----------\n",
    "    val_np: (np.array) the numpy array of val. \n",
    "    \"\"\"\n",
    "    msg_ =  f'\"{name}\" must be in trns_opts but it isnt: {trns_opts}'\n",
    "    assert name in trns_opts, msg_\n",
    "    val = trns_opts[name]\n",
    "    \n",
    "    if isinstance(val, str):\n",
    "        val_list = eval_formula(val, trns_opts)\n",
    "    else:\n",
    "        val_list = val\n",
    "    val_np = np.array(val_list)\n",
    "    src_shape = val_np.shape\n",
    "    trg_shape = eval_formula(trgshp_str, trns_opts)\n",
    "    msg_ = msg_bcast.format(name, trgshp_str, trg_shape, src_shape)\n",
    "\n",
    "    assert len(val_np.shape) == len(trg_shape), msg_\n",
    "\n",
    "    is_bcastble = all((x == y or x == 1 or y == 1) for x, y in\n",
    "                      zip(src_shape, trg_shape))\n",
    "    assert is_bcastble, msg_\n",
    "\n",
    "    return val_np\n",
    "\n",
    "\n",
    "def eval_formula(formula, variables):\n",
    "    \"\"\"\n",
    "    Gets a string formula and uses the `eval` function of python to  \n",
    "    translate it into a python variable. The necessary variables for \n",
    "    translation are provided through the `variables` argument.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    formula (str): a string that can be passed to `eval`.\n",
    "        Example: \"[np.sqrt(dim), 'a', None]\"\n",
    "\n",
    "    variables (dict): a dictionary of variables used in the formula.\n",
    "        Example: {\"dim\": 4}\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    pyobj (object): the translated formula into a python object\n",
    "        Example: [2.0, 'a', None]\n",
    "\n",
    "    \"\"\"\n",
    "    locals().update(variables)\n",
    "    pyobj = eval(formula)\n",
    "    return pyobj\n",
    "\n",
    "\n",
    "def chck_dstrargs(opt, cfgdict, dstr2args, opt2req, parnt_optdstr=None):\n",
    "    \"\"\"\n",
    "    Checks if the distribution arguments are provided correctly. Works \n",
    "    with hirarchical models through recursive applications. Proper error \n",
    "    messages are displayed if one of the checks fails.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    opt: (str) the option name.\n",
    "\n",
    "    cfgdict: (dict) the config dictionary.\n",
    "\n",
    "    dstr2args: (dict) a mapping between distribution and their \n",
    "        required arguments.\n",
    "        \n",
    "    opt2req: (dict) required arguments for an option itself, not \n",
    "        necessarily required by the option's distribution.\n",
    "    \"\"\"\n",
    "    opt_dstr = cfgdict.get(f'{opt}/dstr', 'fixed')\n",
    "\n",
    "    msg_ = f'Unknown {opt}_dstr: it should be one of {list(dstr2args.keys())}'\n",
    "    assert opt_dstr in dstr2args, msg_\n",
    "\n",
    "    opt2req = dict() if opt2req is None else opt2req\n",
    "    optreqs = opt2req.get(opt, tuple())\n",
    "    must_spec = list(dstr2args[opt_dstr]) + list(optreqs)\n",
    "    avid_spec = list(chain.from_iterable(\n",
    "        v for k, v in dstr2args.items() if k != opt_dstr))\n",
    "    avid_spec = [k for k in avid_spec if k not in must_spec]\n",
    "\n",
    "    if opt_dstr == 'fixed':\n",
    "        # To avoid infinite recursive calls, we should end this here.\n",
    "        msg_ = f'\"{opt}\" must be specified.'\n",
    "        if parnt_optdstr is not None:\n",
    "            parnt_opt, parnt_dstr = parnt_optdstr\n",
    "            msg_ += f'\"{parnt_opt}\" was specified as \"{parnt_dstr}\", and'\n",
    "        msg_ += f' \"{opt}\" was specified as \"{opt_dstr}\".'\n",
    "        if len(optreqs) > 0:\n",
    "            msg_ += f' Also, \"{opt}\" requires \"{optreqs}\" to be specified.'\n",
    "        opt_val = cfgdict.get(opt, None)\n",
    "        assert opt_val is not None, msg_\n",
    "    else:\n",
    "        for arg in must_spec:\n",
    "            opt_arg = f'{opt}{arg}'\n",
    "            chck_dstrargs(opt_arg, cfgdict, dstr2args, opt2req, (opt, opt_dstr))\n",
    "\n",
    "    for arg in avid_spec:\n",
    "        opt_arg = f'{opt}{arg}'\n",
    "        opt_arg_val = cfgdict.get(opt_arg, None)\n",
    "        msg_ = f'\"{opt_arg}\" should not be specified, since \"{opt}\" '\n",
    "        msg_ += f'appears to follow the \"{opt_dstr}\" distribution.'\n",
    "        assert opt_arg_val is None, msg_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0368c022",
   "metadata": {},
   "source": [
    "### Toy Example: Latent Parameter Identification\n",
    "\n",
    "Here, we implement a zero-order search method in the `GPMBO` class and use it to recover the charge locations in the following Poisson problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97fc3b6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class GPMBO:\n",
    "    def __init__(self, dim, n_mdl, n_seeds, lr, init_mu, init_std, \n",
    "                 gamma, yb_gamma, rng, optim, tch_device, tch_dtype, \n",
    "                 opt_siglog=True):\n",
    "        mu = init_mu * torch.ones(n_seeds, 1, dim, device=tch_device, dtype=tch_dtype)\n",
    "        mu = torch.nn.Parameter(mu)\n",
    "        assert mu.shape == (n_seeds, 1, dim)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            sig_rot = torch.eye(dim, device=tch_device, dtype=tch_dtype)\n",
    "            sig_rot = sig_rot.reshape(1, 1, dim, dim).expand(n_seeds, 1, dim, dim).clone()\n",
    "            sig_log = torch.full((n_seeds, 1, dim), np.log(init_std), device=tch_device, dtype=tch_dtype)\n",
    "        sig_rot = torch.nn.Parameter(sig_rot)\n",
    "        assert sig_rot.shape == (n_seeds, 1, dim, dim)\n",
    "        sig_log = torch.nn.Parameter(sig_log)\n",
    "        assert sig_log.shape == (n_seeds, 1, dim)\n",
    "        \n",
    "        assert not sig_rot.isnan().any()\n",
    "        \n",
    "        epsilon = rng.normal((n_seeds, n_mdl, dim, 1))\n",
    "        opt_vars = [mu, sig_rot, sig_log] if opt_siglog else [mu, sig_rot]\n",
    "        if optim == 'adam':\n",
    "            opt = torch.optim.Adam(opt_vars, lr=lr)\n",
    "        elif optim == 'sgd':\n",
    "            opt = torch.optim.SGD(opt_vars, lr=lr)\n",
    "        else:\n",
    "            raise ValueError(optim)\n",
    "        \n",
    "        self.mu, self.sig_rot, self.sig_log = mu, sig_rot, sig_log\n",
    "        self.opt = opt\n",
    "        self.rng = rng\n",
    "        self.epsilon = epsilon\n",
    "        self.dim = dim\n",
    "        self.n_mdl = n_mdl\n",
    "        self.n_seeds = n_seeds\n",
    "        self.pi = torch.tensor(np.pi).to(device=tch_device, dtype=tch_dtype)\n",
    "        self.y_base = torch.zeros(n_seeds, 1, device=tch_device, dtype=tch_dtype)\n",
    "        self.gamma = gamma\n",
    "        self.yb_gamma = yb_gamma\n",
    "         \n",
    "    def ask(self):\n",
    "        n_seeds, n_mdl, dim = self.n_seeds, self.n_mdl, self.dim\n",
    "        epsilon, mu = self.epsilon, self.mu\n",
    "        sig_log, sig_rot = self.sig_log, self.sig_rot\n",
    "        \n",
    "        # Computing the \"std\" matrix\n",
    "        sig_rot_ = sig_rot.tril()\n",
    "        assert sig_rot_.shape == (n_seeds, 1, dim, dim)\n",
    "        sig_r = torch.matrix_exp(sig_rot_ - sig_rot_.transpose(-1, -2))\n",
    "        assert sig_r.shape == (n_seeds, 1, dim, dim)\n",
    "        sig_sig = sig_log.exp().reshape(n_seeds, 1, 1, dim)\n",
    "        assert sig_sig.shape == (n_seeds, 1, 1, dim)\n",
    "        sig = sig_r * sig_sig\n",
    "        assert sig.shape == (n_seeds, 1, dim, dim)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_query = sig.matmul(epsilon)\n",
    "            assert x_query.shape == (n_seeds, n_mdl, dim, 1)\n",
    "\n",
    "            x_query = x_query.squeeze(dim=-1)\n",
    "            assert x_query.shape == (n_seeds, n_mdl, dim)\n",
    "\n",
    "            x_query = x_query + self.mu\n",
    "            assert x_query.shape == (n_seeds, n_mdl, dim)\n",
    "            \n",
    "        return x_query\n",
    "    \n",
    "    def tell(self, y):\n",
    "        n_seeds, n_mdl, dim = self.n_seeds, self.n_mdl, self.dim\n",
    "        epsilon, mu = self.epsilon, self.mu\n",
    "        gamma, y_bias = self.gamma, self.y_base\n",
    "        sig_log, sig_rot = self.sig_log, self.sig_rot\n",
    "        yb_gamma = self.yb_gamma\n",
    "        \n",
    "        x = self.ask().detach()\n",
    "        assert x.shape == (n_seeds, n_mdl, dim)\n",
    "        assert y.shape == (n_seeds, n_mdl)\n",
    "        assert not(y.isnan().any())\n",
    "        \n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "        e = (x - mu).unsqueeze(-2)\n",
    "        assert e.shape == (n_seeds, n_mdl, 1, dim)\n",
    "        \n",
    "        sig_rot_ = sig_rot.tril()\n",
    "        assert sig_rot_.shape == (n_seeds, 1, dim, dim)\n",
    "        sig_r = torch.matrix_exp(sig_rot_ - sig_rot_.transpose(-1, -2))\n",
    "        assert sig_r.shape == (n_seeds, 1, dim, dim)\n",
    "        \n",
    "        sig_lam = (-sig_log).exp().reshape(n_seeds, 1, 1, dim)\n",
    "        assert sig_lam.shape == (n_seeds, 1, 1, dim)\n",
    "        sig = sig_r * sig_lam\n",
    "        assert sig.shape == (n_seeds, 1, dim, dim)\n",
    "        eT_sig = e.matmul(sig)\n",
    "        assert eT_sig.shape == (n_seeds, n_mdl, 1, dim)\n",
    "        eT_siginv_e = eT_sig.square().sum(dim=-1).squeeze(-1)\n",
    "        assert eT_siginv_e.shape == (n_seeds, n_mdl)\n",
    "        \n",
    "        sigma_halflogdet = sig_log.sum(dim=-1)\n",
    "        assert sigma_halflogdet.shape == (n_seeds, 1)\n",
    "        logpdf = -0.5 * eT_siginv_e - sigma_halflogdet\n",
    "        assert logpdf.shape == (n_seeds, n_mdl)\n",
    "        \n",
    "        prob_ratio = (logpdf - logpdf.detach()).exp()\n",
    "        assert prob_ratio.shape == (n_seeds, n_mdl)\n",
    "        y_probratio = (y - y_bias) * prob_ratio\n",
    "        assert y_probratio.shape == (n_seeds, n_mdl)\n",
    "        max_obj = y_probratio.mean(dim=-1)\n",
    "        assert max_obj.shape == (n_seeds,)\n",
    "        \n",
    "        min_obj = -max_obj.sum()\n",
    "        min_obj.backward()\n",
    "        \n",
    "        self.opt.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Updating epsilon\n",
    "            deps = rng.normal((n_seeds, n_mdl, dim, 1))\n",
    "            self.epsilon = gamma * epsilon + (1. - self.gamma) * deps\n",
    "            assert self.epsilon.shape == (n_seeds, n_mdl, dim, 1)\n",
    "\n",
    "            # Updating y_bias\n",
    "            dyb = y_bias.mean(dim=-1, keepdims=True)\n",
    "            self.y_bias = yb_gamma * y_bias + (1. - yb_gamma) * dyb\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e49cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpd = dict(dim=2, n_seeds=100, n_true=20, opt_siglog=True, \n",
    "           init_std=0.5, apply_prior=False, e_gamma=0.0, yb_gamma=0.9,\n",
    "           chrg_n=3, n_mdl=100, query_noise=0.0, mbo_lr=0.05,\n",
    "           n_mboiter=400, y_type='potential')\n",
    "\n",
    "# Example 1: Fitting to the potentials without query noise\n",
    "hpd01 = {**hpd}\n",
    "hpd02 = {**hpd01, 'e_gamma': 0.9}\n",
    "hpd03 = {**hpd01, 'e_gamma': 0.9, 'n_mboiter': 40}\n",
    "\n",
    "# Example 2: Fitting to the potentials with query noise\n",
    "hpd04 = {**hpd, 'query_noise':0.05}\n",
    "hpd05 = {**hpd, 'query_noise':0.05, 'n_mboiter': 1000}\n",
    "hpd06 = {**hpd, 'query_noise':0.05, 'mbo_lr': 0.005, 'n_mboiter': 4000}\n",
    "\n",
    "# Example 3: Fitting to the fields with noise\n",
    "hpd07 = {**hpd, 'chrg_n': 1, 'n_mdl': 1000, 'query_noise':0.05, \n",
    "         'mbo_lr': 0.005, 'n_mboiter': 3500, 'y_type': 'field'}\n",
    "hpd08 = {**hpd, 'query_noise':0.05, 'mbo_lr': 0.005,\n",
    "         'n_mboiter': 4000, 'y_type': 'field'}\n",
    "\n",
    "\n",
    "hpd09 = {**hpd, 'query_noise':0.0, 'mbo_lr': 0.005,\n",
    "         'n_mboiter': 40000, 'y_type': 'field', 'chrg_n': 3,\n",
    "         'opt_siglog': False, 'init_std': 0.01, 'n_true': 50}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee5da20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gp_hpd in [hpd04, hpd05, hpd06, hpd07, hpd08, hpd09][-1:]:\n",
    "    locals().update(gp_hpd)\n",
    "\n",
    "    storage_dir = './17_search/'\n",
    "    pathlib.Path(storage_dir).mkdir(parents=True, exist_ok=True)\n",
    "    strgidx = sum(isdir(f'{storage_dir}/{x}') for x in os.listdir(storage_dir))\n",
    "    dtnow = datetime.datetime.now().isoformat(timespec='seconds')\n",
    "    dtnow_ = dtnow[2:].replace('-', '').replace(':', '').replace('.', '')\n",
    "    cfgstrg_dir = f'{storage_dir}/{strgidx:02d}_{dtnow_}'\n",
    "    pathlib.Path(cfgstrg_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with open(f'{cfgstrg_dir}/config.json', \"w\") as outfile:\n",
    "        json.dump(gp_hpd, outfile, indent=4)\n",
    "\n",
    "    sdim = chrg_n * dim\n",
    "    if apply_prior:\n",
    "        tch_normal = torch.distributions.normal.Normal\n",
    "        loc_zero = torch.zeros(sdim, device=tch_device, dtype=tch_dtype)\n",
    "        scale_unit = torch.ones(sdim, device=tch_device, dtype=tch_dtype)\n",
    "        prior_dist = tch_normal(loc=loc_zero, scale=scale_unit)\n",
    "\n",
    "    tch_device = torch.device('cuda:0')\n",
    "    tch_dtype = torch.float32\n",
    "\n",
    "    # Creating the RNG\n",
    "    seeds_arr = (np.arange(n_seeds) * 1000).tolist()\n",
    "    rng = BatchRNG(shape=(n_seeds,), lib='torch', device=tch_device, \n",
    "        dtype=tch_dtype, unif_cache_cols=1_000, norm_cache_cols=5_000)\n",
    "    rng.seed(np.array(seeds_arr))\n",
    "\n",
    "    # Creating the true problem\n",
    "    true_chrg_w = np.ones((n_seeds, chrg_n))\n",
    "    assert true_chrg_w.shape == (n_seeds, chrg_n)\n",
    "    true_chrg_mu = np.array([[-0.5, -0.5],\n",
    "                            [ 0.5,  0.5],\n",
    "                            [ 0.0,  0.0]])[:chrg_n, :]\n",
    "    true_chrg_mu = np.broadcast_to(true_chrg_mu[None, ...], \n",
    "        (n_seeds, chrg_n, dim)).copy()\n",
    "    assert true_chrg_mu.shape == (n_seeds, chrg_n, dim)\n",
    "    true_problem = DeltaProblem(weights=true_chrg_w, \n",
    "        locations=true_chrg_mu,\n",
    "        tch_device=tch_device, tch_dtype=tch_dtype)\n",
    "\n",
    "    true_x = rng.uniform((n_seeds, n_true, dim)) * 2 - 1\n",
    "    assert true_x.shape == (n_seeds, n_true, dim)\n",
    "    if y_type == 'potential':\n",
    "        y_dim = 1\n",
    "        mse_mul = 100\n",
    "        mse_clip = np.inf\n",
    "        true_y = true_problem.potential(true_x).unsqueeze(-1)\n",
    "        assert true_y.shape == (n_seeds, n_true, 1)\n",
    "    elif y_type == 'field':\n",
    "        y_dim = dim\n",
    "        mse_mul = 1\n",
    "        mse_clip = 10\n",
    "        true_y = true_problem.field(true_x)\n",
    "        assert true_y.shape == (n_seeds, n_true, y_dim)\n",
    "    else:\n",
    "        raise ValueError(f'y_type={y_type} undefined')\n",
    "\n",
    "    mbo = GPMBO(dim=sdim, n_mdl=n_mdl, n_seeds=n_seeds, \n",
    "                lr=mbo_lr, init_mu=0.0, init_std=init_std, gamma=e_gamma, \n",
    "                yb_gamma=yb_gamma, rng=rng, optim='adam',\n",
    "                tch_device=tch_device, tch_dtype=tch_dtype, \n",
    "                opt_siglog=opt_siglog)\n",
    "\n",
    "    all_mbo_mu = []\n",
    "    all_mbo_score = []\n",
    "    all_mbo_logstd = []\n",
    "    for mbo_iter in range(n_mboiter):\n",
    "        php_query = mbo.ask()\n",
    "        assert php_query.shape == (n_seeds, n_mdl, sdim)\n",
    "        \n",
    "        # Adding noise to the query to make the problem more challenging\n",
    "        php_query = php_query + query_noise * rng.normal((n_seeds, n_mdl, sdim))\n",
    "        assert php_query.shape == (n_seeds, n_mdl, sdim)\n",
    "\n",
    "        # Running a fake query system\n",
    "        loc_query = php_query.reshape(n_seeds*n_mdl, chrg_n, dim).detach().cpu().numpy()\n",
    "        w_query = torch.ones(n_seeds*n_mdl, chrg_n).detach().cpu().numpy()\n",
    "\n",
    "        problem_query = DeltaProblem(weights=w_query, \n",
    "            locations=loc_query,\n",
    "            tch_device=tch_device, tch_dtype=tch_dtype)\n",
    "\n",
    "        x_query = true_x.reshape(n_seeds, 1, n_true, dim)\n",
    "        x_query = x_query.expand(n_seeds, n_mdl, n_true, dim)\n",
    "        x_query = x_query.reshape(n_seeds*n_mdl, n_true, dim)\n",
    "        \n",
    "        if y_type == 'potential':\n",
    "            y_query_ = problem_query.potential(x_query).unsqueeze(-1)\n",
    "            assert y_query_.shape == (n_seeds*n_mdl, n_true, y_dim)\n",
    "        elif y_type == 'field':\n",
    "            y_query_ = problem_query.field(x_query)\n",
    "            assert y_query_.shape == (n_seeds*n_mdl, n_true, y_dim)\n",
    "        else:\n",
    "            raise ValueError(f'y_type={y_type} undefined')\n",
    "\n",
    "        y_query = y_query_.reshape(n_seeds, n_mdl, n_true, y_dim)\n",
    "        assert y_query.shape == (n_seeds, n_mdl, n_true, y_dim)\n",
    "\n",
    "        y_err = y_query - true_y.reshape(n_seeds, 1, n_true, y_dim)\n",
    "        assert y_err.shape == (n_seeds, n_mdl, n_true, y_dim)\n",
    "\n",
    "        y_mse_ = y_err.square().sum(dim=-1)\n",
    "        assert y_mse_.shape == (n_seeds, n_mdl, n_true)\n",
    "        \n",
    "        y_mse_ = torch.clip(y_mse_ , 0.0, mse_clip)\n",
    "        assert y_mse_.shape == (n_seeds, n_mdl, n_true)\n",
    "        \n",
    "        y_mse = mse_mul * y_mse_.mean(dim=-1)\n",
    "        assert y_mse.shape == (n_seeds, n_mdl)\n",
    "        \n",
    "        if mbo_iter % 100 == 0:\n",
    "            print(f'MSE: {y_mse.mean():.4f} +/- {y_mse.std()/np.sqrt(n_seeds*n_mdl):.4f}')\n",
    "\n",
    "        mbo_score = -y_mse \n",
    "        assert mbo_score.shape == (n_seeds, n_mdl)\n",
    "        \n",
    "        if apply_prior:\n",
    "            mbo_score = mbo_score + prior_dist.log_prob(php_query).sum(dim=-1).detach()\n",
    "            assert mbo_score.shape == (n_seeds, n_mdl)\n",
    "        \n",
    "        all_mbo_score.append(mbo_score.detach().clone())\n",
    "        all_mbo_mu.append(mbo.mu.detach().clone())\n",
    "        all_mbo_logstd.append(mbo.sig_log.detach().clone())\n",
    "        mbo.tell(mbo_score)\n",
    "        \n",
    "    mbo_mus_ = torch.cat(all_mbo_mu, dim=-2).transpose(0, 1)\n",
    "    assert mbo_mus_.shape == (n_mboiter, n_seeds, chrg_n*dim)\n",
    "    mbo_mus = mbo_mus_.reshape(n_mboiter, n_seeds, chrg_n, dim)\n",
    "    assert mbo_mus.shape == (n_mboiter, n_seeds, chrg_n, dim)\n",
    "    mbo_scores = torch.stack(all_mbo_score, dim=0)\n",
    "    assert mbo_scores.shape == (n_mboiter, n_seeds, n_mdl)\n",
    "    mbo_logstds_ = torch.stack(all_mbo_logstd, dim=0).squeeze(-2)\n",
    "    assert mbo_logstds_.shape == (n_mboiter, n_seeds, chrg_n*dim)\n",
    "    mbo_logstds = mbo_logstds_.reshape(n_mboiter, n_seeds, chrg_n, dim)\n",
    "    assert mbo_logstds.shape == (n_mboiter, n_seeds, chrg_n, dim)\n",
    "\n",
    "    # print('The final Gaussian means:')\n",
    "    # a = mbo.mu.reshape(n_seeds, chrg_n*dim).detach().cpu().numpy()\n",
    "    # print(np.array_str(a, precision=3, suppress_small=True) + '\\n' + '-'*80)\n",
    "\n",
    "    # if opt_siglog:\n",
    "    #     print('The final Gaussian stds:')\n",
    "    #     a = mbo.sig_log.exp().reshape(n_seeds, chrg_n*dim).detach().cpu().numpy()\n",
    "    #     print(np.array_str(a, precision=3, suppress_small=True) + '\\n' + '-'*80)\n",
    "\n",
    "\n",
    "    %matplotlib inline\n",
    "    #########################################################\n",
    "    #################### Training Curves ####################\n",
    "    #########################################################\n",
    "    n_rows, n_cols = 1, 2\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*4, n_rows*3), dpi=100, \n",
    "                            sharex=True, sharey=False)\n",
    "    axes = np.array(axes).reshape(n_rows, n_cols)\n",
    "    axes1d = axes.reshape(-1)\n",
    "\n",
    "    ax = axes[0, 0]\n",
    "    y = mbo_scores.mean(-1).detach().cpu().numpy()\n",
    "    assert y.shape == (n_mboiter, n_seeds)\n",
    "    ym = -y.mean(-1)\n",
    "    assert ym.shape == (n_mboiter,)\n",
    "    ci = 2 * y.std(-1) / np.sqrt(n_seeds)\n",
    "    assert ci.shape == (n_mboiter,)\n",
    "    x = np.arange(n_mboiter)\n",
    "    assert x.shape == (n_mboiter,)\n",
    "\n",
    "    ax.plot(x, ym)\n",
    "    ax.fill_between(x, (ym-ci), (ym+ci), color='b', alpha=.1)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Data MSE')\n",
    "\n",
    "    ax = axes[0, 1]\n",
    "    y = mbo_logstds.mean(-1).mean(-1).detach().cpu().numpy()\n",
    "    assert y.shape == (n_mboiter, n_seeds)\n",
    "    ym = y.mean(-1)\n",
    "    assert ym.shape == (n_mboiter,)\n",
    "    ci = 2 * y.std(-1) / np.sqrt(n_seeds)\n",
    "    assert ci.shape == (n_mboiter,)\n",
    "    x = np.arange(n_mboiter)\n",
    "    assert x.shape == (n_mboiter,)\n",
    "\n",
    "    ax.plot(x, ym)\n",
    "    ax.fill_between(x, (ym-ci), (ym+ci), color='b', alpha=.1)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Covariance Log-Det')\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    fig.savefig(f'{cfgstrg_dir}/mse_vs_epoch.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "    #########################################################\n",
    "    ##################### Scatter Plots #####################\n",
    "    #########################################################\n",
    "    assert mbo_mus.shape == (n_mboiter, n_seeds, chrg_n, dim)\n",
    "\n",
    "    plt_mboiters = np.ceil(np.linspace(0, n_mboiter-1, 6)).astype(int).tolist()\n",
    "\n",
    "    n_rows, n_cols = 2, 3\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3), dpi=100, \n",
    "                            sharex=True, sharey=True)\n",
    "    axes = np.array(axes).reshape(n_rows, n_cols)\n",
    "    axes1d = axes.reshape(-1)\n",
    "\n",
    "    for mboiter, ax in zip(plt_mboiters, axes1d):\n",
    "        x1 = mbo_mus[mboiter].detach().cpu().numpy()\n",
    "        assert x1.shape == (n_seeds, chrg_n, dim)\n",
    "        x2 = x1.reshape(n_seeds*chrg_n, dim)\n",
    "        assert x2.shape == (n_seeds*chrg_n, dim)\n",
    "        ax.scatter(x2[:, 0], x2[:, 1], s=1)\n",
    "        ax.set_title(f'GP Iteration: {mboiter}')\n",
    "        ax.set_xlim(-1., 1.)\n",
    "        ax.set_ylim(-1., 1.)\n",
    "        \n",
    "        if mboiter > 0:\n",
    "            ax.scatter(true_chrg_mu[0, :, 0], true_chrg_mu[0, :, 1], \n",
    "                s=60, marker='*', c='r', edgecolor='black')\n",
    "    fig.savefig(f'{cfgstrg_dir}/mu_scatter.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "    #########################################################\n",
    "    ################# Example Trajectories ##################\n",
    "    #########################################################\n",
    "    seed_idxs = list(range(6))\n",
    "\n",
    "    n_rows, n_cols = 2, 3\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*3, n_rows*3), dpi=100, \n",
    "                            sharex=True, sharey=True)\n",
    "    axes = np.array(axes).reshape(n_rows, n_cols)\n",
    "    axes1d = axes.reshape(-1)\n",
    "\n",
    "    for si, ax in zip(seed_idxs, axes1d):\n",
    "        x1 = mbo_mus[:, si, :, :].detach().cpu().numpy()\n",
    "        assert x1.shape == (n_mboiter, chrg_n, dim)    \n",
    "        ax.plot(x1[::1, :, 0], x1[::1, :, 1])#, marker='o', markersize=0.5, mfc='black', mec='black')\n",
    "        \n",
    "        ax.set_title(f'Example Trajectory {si}')\n",
    "        ax.set_xlim(-1., 1.)\n",
    "        ax.set_ylim(-1., 1.)\n",
    "    fig.savefig(f'{cfgstrg_dir}/ex_traj.pdf', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54516e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "jupytext": {
   "formats": "ipynb,py:hydrogen"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Feb 24 2021, 21:46:12) \n[GCC 7.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4aec7983bc6059d1b5d440a2253fd0eef7d09b7a26ee33cf7f8716a3ef03c04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
