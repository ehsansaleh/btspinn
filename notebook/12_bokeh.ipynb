{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import io\n",
    "import time\n",
    "import glob\n",
    "import fnmatch\n",
    "from itertools import chain, cycle\n",
    "from textwrap import dedent\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict as odict\n",
    "from os.path import exists\n",
    "from pandas.api.types import union_categoricals\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import EngFormatter\n",
    "\n",
    "from bokeh.io import push_notebook, show, output_notebook, output_file, save\n",
    "from bokeh.models import Band, ColumnDataSource\n",
    "from bokeh.models import TapTool, Select, Div, BoxZoomTool, ResetTool\n",
    "from bokeh.models import HoverTool, CustomJS, TabPanel, Tabs\n",
    "from bokeh.plotting import figure \n",
    "from bokeh.layouts import gridplot, layout, row, column\n",
    "\n",
    "import bspinn\n",
    "from bspinn.io_utils import get_ovatgrps, drop_unqcols\n",
    "from bspinn.io_cfg import configs_dir, results_dir\n",
    "from bspinn.io_cfg import keyspecs, nullstr\n",
    "from bspinn.io_utils import deep2hie, hie2deep\n",
    "from bspinn.io_utils import save_h5data, load_h5data\n",
    "from bspinn.io_utils import get_h5du, resio, get_dfidxs\n",
    "from bspinn.summary import summarize\n",
    "\n",
    "import yaml\n",
    "from ruamel import yaml as ruyaml\n",
    "from IPython import display as ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflt_dashcfg = dict(xcol='epoch', ycol=None, huecol='fpidxgrp', \n",
    "    colsep=None, rngcol='rng_seed', frame_width=350, \n",
    "    frame_height=235, ncols=4, sharex=True, sharey=True, \n",
    "    header='Ablation Studies', menu_width=250, color_reset='figure',\n",
    "    fig_title='Ablation: {ablname}', colors='snsdark', tooltip=None,\n",
    "    y_axis_type='auto', y_tick_fmt=None, y_tick_lbls=None, \n",
    "    x_axis_type='auto', x_tick_fmt=None, x_tick_lbls=None)\n",
    "\n",
    "#################################################\n",
    "########### Aggregation of RNG Seeds ############\n",
    "#################################################\n",
    "def get_aggdf(hpdf, stdf, xcol, huecol, rngcol, agg='sem'):\n",
    "    grphpdf = drop_unqcols(hpdf)\n",
    "    if huecol not in grphpdf.columns:\n",
    "        grphpdf.insert(0, huecol, hpdf[huecol])\n",
    "    for col in grphpdf.columns:\n",
    "        grphpdf[col] = grphpdf[col].tolist()\n",
    "    grpstdf = stdf.copy()\n",
    "    \n",
    "    grpstdf = grpstdf.replace(nullstr, np.nan)\n",
    "\n",
    "    stcols = [col for col in grpstdf.columns \n",
    "            if col not in (xcol, rngcol)]\n",
    "    hpcols = list(grphpdf.columns)\n",
    "\n",
    "    grpdf = pd.concat([grphpdf, grpstdf], axis=1)\n",
    "    grpbycols = [huecol, xcol]\n",
    "\n",
    "    if callable(agg):\n",
    "        aggpolicy = {c: 'first' for c in hpcols}\n",
    "        aggpolicy.update({c: agg for c in stcols})\n",
    "        aggpolicy.pop(huecol, None)\n",
    "        aggdf = grpdf.groupby(grpbycols, sort=False).agg(aggpolicy)\n",
    "        aggcolsdict = odict()\n",
    "        for col in stcols:\n",
    "            pkg = tuple(zip(*(aggdf[col].tolist())))\n",
    "            aggcolsdict[f'{col}/mean'] = pkg[0]\n",
    "            aggcolsdict[f'{col}/low'] = pkg[1]\n",
    "            aggcolsdict[f'{col}/high'] = pkg[2]\n",
    "        aggdf = pd.concat([aggdf.reset_index().drop(columns=stcols), pd.DataFrame(aggcolsdict)], axis=1)\n",
    "    elif agg in (None, 'mean', 'sem'):\n",
    "        aggpolicy = {c: ['first'] for c in hpcols}\n",
    "        aggpolicy.update({c: ['mean', 'sem'] for c in stcols})\n",
    "        aggdf = grpdf.groupby(grpbycols, sort=False).agg(aggpolicy)\n",
    "        for col in stcols:\n",
    "            aggdf.loc[:, (col, 'low')] = aggdf[col]['mean'] - 1.96 * aggdf[col]['sem']\n",
    "            aggdf.loc[:, (col, 'high')] = aggdf[col]['mean'] + 1.96 * aggdf[col]['sem']\n",
    "\n",
    "        aggdf = aggdf.reindex(columns=hpcols+stcols, level=0)\n",
    "        aggdf.columns = aggdf.columns.map('/'.join)\n",
    "        aggdf = aggdf.reset_index().drop(columns=huecol)\n",
    "\n",
    "        scc = [col for col in aggdf.columns if not col.endswith('/first')]\n",
    "        aggdf = aggdf.rename(columns={f'{col}/first': col for col in hpcols})\n",
    "        aggdf = aggdf[hpcols + scc]\n",
    "    else:\n",
    "        raise ValueError(f'error_band={error_band} not defined')\n",
    "    \n",
    "    outdict = dict(aggdf=aggdf, hpcols=hpcols, stcols=stcols)\n",
    "    return outdict\n",
    "\n",
    "class BStrapAgg:\n",
    "    stat2func = {'mean': np.mean, 'median': np.median}\n",
    "\n",
    "    def __init__(self, n_boot=20, q=(5, 95), \n",
    "        stat='mean', seed=12345):\n",
    "        self.n_boot = n_boot\n",
    "        self.q = q\n",
    "        self.stat_f = self.stat2func[stat]\n",
    "        self.np_random = np.random.RandomState(seed)\n",
    "\n",
    "    def __call__(self, series):\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            v = series.values\n",
    "            n = v.size\n",
    "            rsv = self.np_random.choice(v, self.n_boot*n, replace=True)\n",
    "            x = rsv.reshape(self.n_boot, n)\n",
    "            m = self.stat_f(x, axis=1)\n",
    "            l = np.percentile(m, self.q[0])\n",
    "            h = np.percentile(m, self.q[1])\n",
    "            return (m.mean(), l, h)\n",
    "\n",
    "#################################################\n",
    "########### Dashboard Data & Building ###########\n",
    "#################################################\n",
    "def get_dflt_ablspec(hpdf, fpgrps, huecol='fpidxgrp', ablcol='ablgrp'):\n",
    "    grpspec = []\n",
    "    uhpdf = hpdf.drop_duplicates().copy()\n",
    "    uhpdf = drop_unqcols(uhpdf.drop('fpidx', axis=1))\n",
    "    uhpdf = uhpdf.reset_index(drop=True)\n",
    "    uhpidf = uhpdf.copy().set_index(huecol)\n",
    "    for ii, fpidxs in enumerate(fpgrps):\n",
    "        grphpdf = drop_unqcols(uhpidf.loc[fpidxs].reset_index(huecol))\n",
    "        grpid = set(grphpdf.columns).difference({ablcol, huecol})\n",
    "        grpid = sorted(grpid)\n",
    "        grpspec.append(dict(name=', '.join(grpid), columns=[grpid]))\n",
    "    return grpspec\n",
    "\n",
    "def get_dashdata(data, ymlpath, write_yml=False,\n",
    "    en_exclude=True, en_include=True):\n",
    "    if exists(ymlpath):\n",
    "        with open(ymlpath, 'r') as fp:\n",
    "            dashconfig = ruyaml.load(fp, ruyaml.RoundTripLoader)\n",
    "    else:\n",
    "        dashconfig = dict()\n",
    "\n",
    "    figspec = dashconfig.setdefault('figures', dict())\n",
    "    aggcfg = dashconfig.setdefault('aggregate', dict())\n",
    "    dropcfg = dashconfig.setdefault('drop', dict())\n",
    "    renamecfg = dashconfig.setdefault('rename', dict())\n",
    "    plotcfg = dashconfig.setdefault('plot', dict())\n",
    "\n",
    "    #################################################\n",
    "    ############### Aggregator Setup ################\n",
    "    #################################################\n",
    "    aggtype = aggcfg.setdefault('type', 'mean')\n",
    "    if aggtype == 'bootstrap':\n",
    "        n_boot = aggcfg.setdefault('n_boot', 20)\n",
    "        q = aggcfg.setdefault('q', [5, 95])\n",
    "        stat = aggcfg.setdefault('stat', 'mean')\n",
    "        aggregator = BStrapAgg(n_boot=n_boot, q=q, stat=stat, seed=12345)\n",
    "        assert len(aggcfg) == 4\n",
    "    elif aggtype in ('sem', 'mean'):\n",
    "        aggregator = 'sem'\n",
    "        assert len(aggcfg) == 1\n",
    "    else:\n",
    "        raise ValueError(f'aggregation type={aggtype} not defined')\n",
    "\n",
    "    #################################################\n",
    "    ########### Column Definition Options ###########\n",
    "    #################################################\n",
    "    drop_colpats = dropcfg.setdefault('columns', [])\n",
    "    assert len(dropcfg) == 1\n",
    "\n",
    "    col_renamer = renamecfg.setdefault('columns', dict())\n",
    "    col_replacer = renamecfg.setdefault('colrplc', dict())\n",
    "    assert len(renamecfg) == 2\n",
    "    \n",
    "    for opt, dfltoptval in dflt_dashcfg.items():\n",
    "        optval = plotcfg.get(opt, dfltoptval)\n",
    "        if opt.endswith('col'):\n",
    "            optval = col_renamer.get(optval, optval)\n",
    "            if isinstance(optval, str):\n",
    "                for kk, vv in col_replacer.items():\n",
    "                    optval = optval.replace(kk, vv)\n",
    "        plotcfg[opt] = optval\n",
    "    assert len(plotcfg) == len(dflt_dashcfg), plotcfg\n",
    "\n",
    "    xcol = plotcfg['xcol']\n",
    "    huecol = plotcfg['huecol']\n",
    "    rngcol = plotcfg['rngcol']\n",
    "    \n",
    "    #################################################\n",
    "    ################ Data Processing ################\n",
    "    #################################################\n",
    "    dashdata = []\n",
    "    for method, hpdf, stdf in data:\n",
    "        meth_ablspec = figspec.setdefault(method, list())\n",
    "\n",
    "        # Getting a copy of the input dataframes\n",
    "        hpdf, stdf = hpdf.copy(), stdf.copy()\n",
    "\n",
    "        # Dropping some stat columns\n",
    "        if drop_colpats is not None:\n",
    "            stdfcols = stdf.columns.tolist()\n",
    "            drop_cols = chain.from_iterable(fnmatch.filter(stdfcols, pat) \n",
    "                for pat in drop_colpats)\n",
    "            stdf = stdf.drop(columns=drop_cols)\n",
    "\n",
    "        # Shortening the fpidx and fpidxgrp columns to save space on html\n",
    "        hpdf['fpidx'] = hpdf['fpidx'].cat.codes\n",
    "        hpdf[huecol] = hpdf[huecol].cat.codes\n",
    "\n",
    "        # Renaming the columns\n",
    "        if col_renamer is not None:\n",
    "            stdf = stdf.rename(columns=col_renamer)\n",
    "        if col_replacer is not None:\n",
    "            colsrplcd = dict()\n",
    "            for col in stdf.columns.tolist():\n",
    "                colrp = col\n",
    "                for kk, vv in col_replacer.items():\n",
    "                    colrp = colrp.replace(kk, vv)\n",
    "                colsrplcd[col] = colrp\n",
    "            stdf = stdf.rename(columns=colsrplcd)\n",
    "\n",
    "        # Grouping the hyper-parameters \n",
    "        fpgrps = get_ovatgrps(hpdf)\n",
    "        dfltabldefs = get_dflt_ablspec(hpdf, fpgrps, huecol, 'ablgrp')\n",
    "        grphpcols = [tuple(x['columns'][0]) for x in dfltabldefs]\n",
    "        hpcols2fpgrp = dict(zip(grphpcols, fpgrps))\n",
    "        \n",
    "        # Adding existing ablations that do not exist in\n",
    "        # the ablation config file\n",
    "        mcols = [l['columns'] for l in meth_ablspec]\n",
    "        mcols = [x if x != '*' else grphpcols for x in mcols]\n",
    "        mohpc = chain.from_iterable(mcols)\n",
    "        mohpc = [tuple(sorted(x)) for x in mohpc]\n",
    "        used_fpgrpidxs = set(chain.from_iterable(hpcols2fpgrp[x] for x in mohpc))\n",
    "        for fpgrp, abldict in zip(fpgrps, dfltabldefs):\n",
    "            if any(fpgrpidx not in used_fpgrpidxs for fpgrpidx in fpgrp):\n",
    "                meth_ablspec.append(abldict)\n",
    "\n",
    "        # Adding the method column\n",
    "        hpdf.insert(0, 'method', method)\n",
    "\n",
    "        # Adding the ablation group column\n",
    "        hpdfgrp_list, stdfgrp_list = [], []\n",
    "        for abldict in meth_ablspec:\n",
    "            ablname = abldict['name']\n",
    "            exclist = abldict.get('exclude', [])\n",
    "            exclist = exclist if en_exclude else []\n",
    "            inclist = abldict.get('include', [])\n",
    "            inclist = inclist if en_include else []\n",
    "            allhpcols = abldict['columns'] if (abldict['columns'] != '*') else grphpcols\n",
    "            for hpcols in allhpcols:\n",
    "                fpgrp = hpcols2fpgrp[tuple(sorted(hpcols))]\n",
    "                ii = hpdf[huecol].isin(fpgrp)\n",
    "                if len(exclist) > 0:\n",
    "                    exc_il = [get_dfidxs(hpdf, excdict) for excdict in exclist]\n",
    "                    jj = np.stack(exc_il, axis=1).any(axis=1)\n",
    "                    ii = np.logical_and(ii, np.logical_not(jj))\n",
    "                if len(inclist) > 0:\n",
    "                    inc_il = [get_dfidxs(hpdf, incdict) for incdict in inclist]\n",
    "                    jj = np.stack(inc_il, axis=1).any(axis=1)\n",
    "                    ii = np.logical_and(ii, jj)\n",
    "                hpdfgrp = hpdf[ii].copy()\n",
    "                stdfgrp = stdf[ii]\n",
    "                hpdfgrp.insert(1, 'ablgrp', ablname)\n",
    "                hpdfgrp_list.append(hpdfgrp)\n",
    "                stdfgrp_list.append(stdfgrp)\n",
    "        hpdf = pd.concat(hpdfgrp_list, axis=0, ignore_index=True)\n",
    "        stdf = pd.concat(stdfgrp_list, axis=0, ignore_index=True)\n",
    "\n",
    "        hpdf = hpdf.fillna(nullstr)\n",
    "        stdf = stdf.fillna(nullstr)\n",
    "\n",
    "        hpdf, stdf = hpdf, stdf\n",
    "        for fig_idx, (ablname, ablhpdf) in enumerate(hpdf.groupby('ablgrp', sort=False)):\n",
    "            ablstdf = stdf.loc[ablhpdf.index.values]\n",
    "            aggdict = get_aggdf(ablhpdf, ablstdf, xcol, huecol, rngcol, aggregator)\n",
    "            aggdf, hpcols, stcols = aggdict['aggdf'], aggdict['hpcols'], aggdict['stcols']\n",
    "            dashdata.append((method, ablname, aggdf, hpcols, stcols))\n",
    "\n",
    "    if write_yml: \n",
    "        if exists(ymlpath):\n",
    "            with open(ymlpath, 'w') as fp:\n",
    "                ruyaml.dump(dashconfig, fp, ruyaml.RoundTripDumper)\n",
    "        else:\n",
    "            with open(ymlpath, 'w') as fp:\n",
    "                yaml.dump(dashconfig, fp, sort_keys=False, default_flow_style=None)\n",
    "\n",
    "    outdict = dict(plotcfg)\n",
    "    outdict['data'] = dashdata\n",
    "    outdict.pop('rngcol', None)\n",
    "    return outdict\n",
    "\n",
    "def build_dashboard(doc, data, xcol, ycol, header,\n",
    "    huecol, fig_title, colors=None, frame_width=350, \n",
    "    frame_height=235, ncols=4, sharex=True, sharey=True, \n",
    "    tooltip=None, menu_width=150, colsep=None, color_reset='figure',\n",
    "    y_axis_type='auto', y_tick_fmt=None, y_tick_lbls=None, \n",
    "    x_axis_type='auto', x_tick_fmt=None, x_tick_lbls=None):\n",
    "\n",
    "    if colors in (None, 'snsdark'):\n",
    "        colors = ['#001c7f', '#b1400d', '#12711c', '#8c0800', '#591e71', \n",
    "                  '#592f0d', '#a23582', '#3c3c3c', '#b8850a', '#006374']\n",
    "    else:\n",
    "        assert isinstance(colors, list)\n",
    "\n",
    "    if fig_title is None:\n",
    "        fig_title = 'Ablation: {ablname}'\n",
    "\n",
    "    all_bkfigdata = []\n",
    "    all_tabbkfigdata = []\n",
    "    tabs_list = []\n",
    "\n",
    "    tab2data = odict()\n",
    "    for tabname, ablname, aggdf, hpcols, stcols in data:\n",
    "        figsdata = tab2data.setdefault(tabname, [])\n",
    "        figsdata.append((ablname, aggdf, hpcols, stcols))\n",
    "        if ycol is None:\n",
    "            ycol = [c[:-5] for c in aggdf.columns \n",
    "                if c.endswith('/mean')][-1]\n",
    "    assert ycol is not None\n",
    "    assert sharex in (True, False, 'tab', 'all', 'none')\n",
    "    assert sharey in (True, False, 'tab', 'all', 'none')\n",
    "    assert color_reset in ('figure', 'tab', 'all')\n",
    "    if color_reset == 'all':\n",
    "        colors_cycle = cycle(colors)\n",
    "    for tabname, figsdata in tab2data.items():\n",
    "        n_tabfig = len(figsdata)\n",
    "        n_rows = int(np.ceil(n_tabfig / ncols))\n",
    "        screen_width = int(frame_width*(ncols+0.1))\n",
    "        screen_hight = int(frame_height*(n_rows+0.1))\n",
    "        tab_bkfigdata = []\n",
    "\n",
    "        if color_reset == 'tab':\n",
    "            colors_cycle = cycle(colors)\n",
    "        for fig_idx, (ablname, aggdf, hpcols, stcols) in enumerate(figsdata):\n",
    "            ax_row, ax_col = fig_idx // ncols, fig_idx % ncols\n",
    "            idcols = [col for col in hpcols if col not in ('fpidx', huecol)]\n",
    "            if tooltip is not None:\n",
    "                idcols += tooltip\n",
    "\n",
    "            show_xaxis = (sharex in (False, 'none')) or (ax_row == (n_rows-1))\n",
    "            show_yaxis = (sharey in (False, 'none')) or (ax_col == 0)\n",
    "\n",
    "            zoomtool = BoxZoomTool()\n",
    "            figtools = [zoomtool, 'reset,pan,wheel_zoom']\n",
    "            \n",
    "            hover_opts = dict(show_arrow=False,\n",
    "                line_policy='next', mode='mouse', toggleable=False)\n",
    "            \n",
    "            figure_opts = dict(y_axis_type=y_axis_type, \n",
    "                x_axis_type=x_axis_type, frame_height=frame_height, \n",
    "                frame_width=frame_width, sizing_mode='inherit')\n",
    "            \n",
    "            fig = figure(**figure_opts, tools=figtools)\n",
    "            fig.toolbar.active_drag = zoomtool\n",
    "\n",
    "            source_list = []\n",
    "            fpidf_list = []\n",
    "            if color_reset == 'figure':\n",
    "                colors_cycle = cycle(colors)\n",
    "            for lineidx, (fpidx, fpidf) in enumerate(aggdf.groupby(huecol, sort=False)):\n",
    "                color = next(colors_cycle)\n",
    "                fpidf = fpidf.copy()\n",
    "\n",
    "                fpidf = fpidf.set_index(xcol)\n",
    "                fpidf = fpidf.replace(np.inf, np.nan)\n",
    "                fpidf = fpidf.interpolate(method='index', limit_direction='both')\n",
    "                fpidf = fpidf.reset_index()\n",
    "\n",
    "                for col in fpidf.columns:\n",
    "                    if fpidf[col].dtype == 'bool':\n",
    "                        fpidf[col] = fpidf[col].astype(str)\n",
    "\n",
    "                fpidf['y/mean'] = fpidf[f'{ycol}/mean']\n",
    "                fpidf['y/low'] = fpidf[f'{ycol}/low']\n",
    "                fpidf['y/high'] = fpidf[f'{ycol}/high']\n",
    "                \n",
    "                source = ColumnDataSource(fpidf)\n",
    "                line = fig.line(x=xcol, y=f'y/mean', source=source,  \n",
    "                    legend_label=str(fpidx), color=color, line_width=5)\n",
    "\n",
    "                tooltip_tups = [(col, '@{'+col+'}') for col in idcols \n",
    "                    if not (fpidf[col] == nullstr).values.all()]\n",
    "                if len(tooltip_tups) > 0:\n",
    "                    fig.add_tools(HoverTool(renderers=[line], \n",
    "                        tooltips=tooltip_tups, **hover_opts))\n",
    "                \n",
    "                band = Band(base=xcol, lower=f'y/low', \n",
    "                    upper=f'y/high', source=source,\n",
    "                    fill_alpha=0.3, fill_color=color)\n",
    "                fig.add_layout(band)\n",
    "                source_list.append(source)\n",
    "                fpidf_list.append(fpidf)\n",
    "\n",
    "            fontsize = \"10pt\"\n",
    "            if show_xaxis:\n",
    "                fig.xaxis.axis_label = xcol\n",
    "                fig.xaxis.axis_label_text_font_size = fontsize\n",
    "                fig.xaxis.major_label_text_font_size = fontsize\n",
    "                fig.xaxis.axis_label_text_color = \"black\"\n",
    "            else:\n",
    "                fig.xaxis.visible = False\n",
    "\n",
    "            if show_yaxis:\n",
    "                ycol_ = ycol if len(ycol) <= 50 else ycol.split(colsep)[0]\n",
    "                fig.yaxis.axis_label = ycol_\n",
    "                fig.yaxis.axis_label_text_font_size = fontsize\n",
    "                fig.yaxis.major_label_text_font_size = fontsize\n",
    "                fig.yaxis.axis_label_text_color = \"black\"\n",
    "            else:\n",
    "                fig.yaxis.visible = False\n",
    "\n",
    "            fig.title.text = fig_title.format(ablname=ablname) \n",
    "            fig.legend.visible = False \n",
    "            fig.legend.destroy()\n",
    "\n",
    "            for tick_fmt, tick_lbls, axis in [(x_tick_fmt, x_tick_lbls, fig.xaxis),\n",
    "                                              (y_tick_fmt, y_tick_lbls, fig.yaxis)]:\n",
    "                if tick_lbls is not None:\n",
    "                    axis.ticker = tick_lbls\n",
    "                if tick_fmt == 'eng':\n",
    "                    msg_ = f'for eng fmt, tick labels must be specified'\n",
    "                    assert tick_lbls is not None, msg_\n",
    "                    mpleng = EngFormatter()\n",
    "                    engfmtr = lambda n: mpleng.format_eng(n).replace(' ', '')\n",
    "                    axis.major_label_overrides = {x: engfmtr(x) for x in tick_lbls}\n",
    "                else:   \n",
    "                    assert tick_fmt in ('eng', None)\n",
    "            \n",
    "            fig.outline_line_color = 'black'\n",
    "            fig.min_border = 10\n",
    "\n",
    "            figdict=dict(fig=fig, source_list=source_list, fpidf_list=fpidf_list)\n",
    "            tab_bkfigdata.append(figdict)\n",
    "\n",
    "        all_bkfigdata += tab_bkfigdata\n",
    "        all_tabbkfigdata.append(tab_bkfigdata)\n",
    "        tab_figs = [x['fig'] for x in tab_bkfigdata]\n",
    "        gridfigs = gridplot(tab_figs, ncols=ncols, sizing_mode='inherit')\n",
    "        tabpanel = TabPanel(child=gridfigs, title=tabname, closable=True)\n",
    "        tabs_list.append(tabpanel)\n",
    "    \n",
    "    tabgridfigs = Tabs(tabs=tabs_list, sizing_mode='inherit')\n",
    "    all_figs = [x['fig'] for x in all_bkfigdata]\n",
    "    all_tabfigs = [[x['fig'] for x in tab_bkfigdata] for tab_bkfigdata in all_tabbkfigdata]\n",
    "    \n",
    "    if sharey in (True, 'all'):\n",
    "        for fig in all_figs:\n",
    "            fig.y_range = all_figs[0].y_range\n",
    "    elif sharey == 'tab':\n",
    "        for tabfigs in all_tabfigs:\n",
    "            for fig in tabfigs:\n",
    "                fig.y_range = tabfigs[0].y_range\n",
    "    elif sharey in (False, 'none'):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f'sharey={sharey} not defined')\n",
    "    \n",
    "    if sharex in (True, 'all'):\n",
    "        for fig in all_figs:\n",
    "            fig.x_range = all_figs[0].x_range\n",
    "    elif sharex == 'tab':\n",
    "        for tabfigs in all_tabfigs:\n",
    "            for fig in tabfigs:\n",
    "                fig.x_range = tabfigs[0].x_range\n",
    "    elif sharex in (False, 'none'):\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(f'sharex={sharex} not defined')\n",
    "\n",
    "    # Menu update callback in javascript\n",
    "    code_js = \"\"\"\n",
    "        ////////////////////////////////////////////////////\n",
    "        ///////////////// Menu Separation //////////////////\n",
    "        ////////////////////////////////////////////////////\n",
    "        var opts, menu, val;\n",
    "        var ccd = cdeep;\n",
    "        var sects = sectscds.data[\"sects\"];\n",
    "        for (let i=0; i < n_menu; i++) {\n",
    "            if (i <= menu_idx) {\n",
    "                if (i < menu_idx) {\n",
    "                    val = sects[i];\n",
    "                } else {\n",
    "                    val = right_menus[0].value;\n",
    "                    sects[i] = val;\n",
    "                }\n",
    "                ccd = ccd[val];\n",
    "            } else {\n",
    "                menu = right_menus[i-menu_idx];\n",
    "                if (ccd == null) {\n",
    "                    val = null;\n",
    "                    menu.visible = false;\n",
    "                    menu.options = [];\n",
    "                } else {\n",
    "                    opts = Object.keys(ccd);\n",
    "                    if (opts.includes(sects[i])) {\n",
    "                        val = sects[i];\n",
    "                    } else {\n",
    "                        val = opts[0];\n",
    "                    }\n",
    "                    ccd = ccd[val];\n",
    "                    menu.visible = true;\n",
    "                    menu.options = opts;\n",
    "                    menu.value = val;\n",
    "                }\n",
    "                sects[i] = val;\n",
    "            }\n",
    "\n",
    "        }\n",
    "        // The new axis\n",
    "        var ycol_new = sects.filter(Boolean).join(colsep);\n",
    "        \n",
    "        ////////////////////////////////////////////////////\n",
    "        ////////////////// Source Update ///////////////////\n",
    "        ////////////////////////////////////////////////////\n",
    "        // var ycol_new = cb_obj.value;\n",
    "        const statnames = [\"mean\", \"low\", \"high\"];\n",
    "        for (let j=0; j<all_srcs.length; j++) {\n",
    "            var sdata = all_srcs[j].data;\n",
    "            for (let k=0; k< statnames.length; k++) {\n",
    "                var stn = statnames[k];\n",
    "                var ycol_stn = ycol_new.concat(colsep, stn);\n",
    "                var y_stn = \"y\".concat(colsep, stn);\n",
    "                sdata[y_stn] = [];\n",
    "                if (ycol_stn in sdata) {\n",
    "                    for (let i=0;i<sdata[ycol_stn].length; i++) {\n",
    "                        sdata[y_stn].push(sdata[ycol_stn][i]);\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for (let j=0; j<all_srcs.length; j++) {\n",
    "            all_srcs[j].change.emit();\n",
    "        }\n",
    "\n",
    "        var axlbl = ycol_new;\n",
    "        if (axlbl.length > 50) {\n",
    "            axlbl = axlbl.split(colsep)[0];\n",
    "        }\n",
    "        for (let j=0; j<all_yaxes.length; j++) {\n",
    "            all_yaxes[j].axis_label = axlbl;\n",
    "        }\n",
    "    \"\"\"\n",
    "    # Creating Menus and seperating the columns\n",
    "    if colsep is None:\n",
    "        colsep = '######'\n",
    "    cdeep = hie2deep({c: None for c in stcols}, sep=colsep)\n",
    "    n_menu = max(c.count(colsep) for c in stcols) + 1\n",
    "    sects = ycol.split(colsep)\n",
    "    sects += (n_menu - len(sects)) * [None]\n",
    "    all_menus = []\n",
    "    dd = cdeep\n",
    "    for i in range(n_menu):\n",
    "        sect = sects[i]\n",
    "        assert (dd is None) == (sect is None)\n",
    "        opts = [] if sect is None else list(dd.keys())\n",
    "        ddd = dict(title='Y-Axis') if i == 0 else dict(title=\"      \")\n",
    "        menu = Select(options=opts, value=sect, **ddd,\n",
    "            width=menu_width, height=50, sizing_mode='fixed')\n",
    "        if sect is None:\n",
    "            menu.visible = False\n",
    "        menu.align = 'end'\n",
    "        if dd is not None:\n",
    "            dd = dd[sect]\n",
    "        all_menus.append(menu)\n",
    "\n",
    "    sectscds = ColumnDataSource(data={'sects': sects})\n",
    "    all_srcs = list(chain.from_iterable(figdata['source_list'] \n",
    "        for figdata in all_bkfigdata))\n",
    "    all_yaxes = [fig.yaxis[0] for fig in all_figs]\n",
    "\n",
    "    for menu_idx, menu in enumerate(all_menus):\n",
    "        menu_args = dict(cdeep=cdeep, n_menu=n_menu, \n",
    "            menu_idx=menu_idx, right_menus=all_menus[menu_idx:], \n",
    "            sectscds=sectscds, colsep=colsep)\n",
    "        data_args = dict(all_srcs=all_srcs, all_figs=all_figs, \n",
    "            all_yaxes=all_yaxes)\n",
    "        jscb = CustomJS(args={**menu_args, **data_args}, code=code_js)\n",
    "        menu.js_on_change('value', jscb)\n",
    "    \n",
    "    # heading fills available width\n",
    "    heading = Div(text=f'<h1 style=\"text-align: center\">{header}</h1>', \n",
    "        width=screen_width-menu_width*n_menu, height=50, \n",
    "        sizing_mode='stretch_width')\n",
    "    \n",
    "    fulllayout = column(row(heading, *all_menus, sizing_mode='stretch_width'), \n",
    "        tabgridfigs, sizing_mode='stretch_both')\n",
    "    \n",
    "    if doc is not None:\n",
    "        doc.add_root(fulllayout)\n",
    "    else:\n",
    "        return fulllayout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = './12_bokeh'\n",
    "! mkdir -p {workdir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The High-Dimensional Poisson Dashboard (Version 4)\n",
    "\n",
    "This part relies on data generated in the `13_hdpviz.ipynb` notebook. In particular, the `13_hdpviz/02_hdpviz.h5` file must be present for this part to work.\n",
    "\n",
    "Some of the improvements over the previous version were:\n",
    "\n",
    "1. This dashboard added the deterministic radius sampling scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrypath = f'13_hdpviz/02_hdpviz.h5'\n",
    "get_h5du(smrypath, verbose=True, detailed=False)\n",
    "data = load_h5data(smrypath)\n",
    "hpdf = data['hp']\n",
    "statdf = data['stat']\n",
    "\n",
    "hpdf = hpdf.sort_values(by=['dim', 'trg/btstrp', 'srfpts/dblsmpl', 'vol/n'])\n",
    "i1 = hpdf.index.values\n",
    "hpdf = hpdf.reset_index(drop=True)\n",
    "statdf = statdf.loc[i1, :].reset_index(drop=True)\n",
    "\n",
    "# 13_hdpviz/02_hdpviz.h5 is not generated by the original summary script, \n",
    "# so we need to make some adjustments to it to avoid erros.\n",
    "hpdf['fpidx'] = pd.Categorical(hpdf['fpidx'])\n",
    "hpdf['fpidxgrp'] = pd.Categorical(hpdf['fpidxgrp'])\n",
    "for col in hpdf.columns:\n",
    "    if hpdf.dtypes[col] == 'category':\n",
    "        hpdf[col] = hpdf[col].cat.add_categories(nullstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymlpath = f'{workdir}/06_poisshidim.yml'\n",
    "\n",
    "all_dims = sorted(hpdf['dim'].unique().tolist())\n",
    "data = []\n",
    "for dim in all_dims:\n",
    "    didx = (hpdf['dim'] == dim)\n",
    "    dhpdf = hpdf.loc[didx, :].reset_index(drop=True)\n",
    "    dstdf = statdf.loc[didx, :].reset_index(drop=True)\n",
    "    data.append((f'{dim}-Dimensional', dhpdf, dstdf))\n",
    "\n",
    "dashdata = get_dashdata(data, ymlpath, write_yml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllayout = build_dashboard(None, **dashdata)\n",
    "output_file(f'{workdir}/06_poisshidim.html')\n",
    "save(fulllayout, title=dashdata['header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The High-Dimensional Poisson Dashboard (Version 3)\n",
    "\n",
    "This was the second earliest attempt at collecting the high-dimensional poisson problem results.\n",
    "\n",
    "Some of the improvements over the previous version were:\n",
    "\n",
    "1. The Poisson problem dimension range is [2, 3, 4, 5, 6, 7, 8, 9, 10].\n",
    "\n",
    "2. The target regularization weight for bootstrapping was tuned properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrypath = f'../summary/05_poisshidim.h5'\n",
    "get_h5du(smrypath, verbose=True, detailed=False)\n",
    "data = load_h5data(smrypath)\n",
    "hpdf = data['hp']\n",
    "statdf = data['stat']\n",
    "\n",
    "hpdf = hpdf.sort_values(by=['dim', 'trg/btstrp', 'srfpts/dblsmpl', 'vol/n'])\n",
    "i1 = hpdf.index.values\n",
    "hpdf = hpdf.reset_index(drop=True)\n",
    "statdf = statdf.loc[i1, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymlpath = f'{workdir}/05_poisshidim.yml'\n",
    "\n",
    "all_dims = sorted(hpdf['dim'].unique().tolist())\n",
    "data = []\n",
    "for dim in all_dims:\n",
    "    didx = (hpdf['dim'] == dim)\n",
    "    dhpdf = hpdf.loc[didx, :].reset_index(drop=True)\n",
    "    dstdf = statdf.loc[didx, :].reset_index(drop=True)\n",
    "    data.append((f'{dim}-Dimensional', dhpdf, dstdf))\n",
    "\n",
    "dashdata = get_dashdata(data, ymlpath, write_yml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllayout = build_dashboard(None, **dashdata)\n",
    "output_file(f'{workdir}/05_poisshidim.html')\n",
    "save(fulllayout, title=dashdata['header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The High-Dimensional Poisson Dashboard (Version 2)\n",
    "\n",
    "This was the second earliest attempt at collecting the high-dimensional poisson problem results.\n",
    "\n",
    "Some of the improvements over the previous version were:\n",
    "\n",
    "1. A single Poisson charge was placed at zero for all experiments.\n",
    "\n",
    "2. No initial condition was applied here at all.\n",
    "\n",
    "The following issues exist with this benchmarking:\n",
    "\n",
    "1. The Poisson problem dimension range is [8, 16].\n",
    "\n",
    "2. The target regularization weight for bootstrapping was still not set properly.\n",
    "\n",
    "3. A very small number of bootstrapped trainings diverged due to Number 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrypath = f'../summary/04_poisshidim.h5'\n",
    "get_h5du(smrypath, verbose=True, detailed=False)\n",
    "data = load_h5data(smrypath)\n",
    "hpdf = data['hp']\n",
    "statdf = data['stat']\n",
    "\n",
    "i1 = (hpdf['trg/btstrp'] == True)\n",
    "i2 = (hpdf['trg/btstrp'] == False)\n",
    "hpdf_bts = hpdf[i1].reset_index(drop=True)\n",
    "statdf_bts = statdf[i1].reset_index(drop=True)\n",
    "hpdf_mse = hpdf[i2].reset_index(drop=True)\n",
    "statdf_mse = statdf[i2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_idxs = []\n",
    "for fpidxgrp, hpdf in hpdf_bts.groupby('fpidxgrp'):\n",
    "    if hpdf.shape[0] < 1:\n",
    "        continue\n",
    "    stdf = statdf_bts.loc[hpdf.index, :]\n",
    "\n",
    "    rsstdf = stdf.groupby('rng_seed').agg('max').reset_index()\n",
    "    goodrs = rsstdf.loc[rsstdf['loss/total'] < 1, 'rng_seed']\n",
    "    goodinic = stdf['rng_seed'].isin(goodrs)\n",
    "    stable_idxs.append(goodinic[goodinic].index.values)\n",
    "\n",
    "keepidxs = np.concatenate(stable_idxs, axis=0)\n",
    "\n",
    "hpdf_bts = hpdf_bts.loc[keepidxs].reset_index(drop=True)\n",
    "statdf_bts = statdf_bts.loc[keepidxs].reset_index(drop=True)\n",
    "\n",
    "# Combining filtered bootstrapping and mse data-frames\n",
    "hpdf = pd.concat([hpdf_bts, hpdf_mse], axis=0, ignore_index=True)\n",
    "statdf = pd.concat([statdf_bts, statdf_mse], axis=0, ignore_index=True)\n",
    "\n",
    "hpdf = hpdf.sort_values(by=['dim', 'trg/btstrp', 'srfpts/dblsmpl', 'vol/n'])\n",
    "i1 = hpdf.index.values\n",
    "hpdf = hpdf.reset_index(drop=True)\n",
    "statdf = statdf.loc[i1, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymlpath = f'{workdir}/04_poisshidim.yml'\n",
    "\n",
    "all_dims = sorted(hpdf['dim'].unique().tolist())\n",
    "data = []\n",
    "for dim in all_dims:\n",
    "    didx = (hpdf['dim'] == dim)\n",
    "    dhpdf = hpdf.loc[didx, :].reset_index(drop=True)\n",
    "    dstdf = statdf.loc[didx, :].reset_index(drop=True)\n",
    "    data.append((f'{dim}-Dimensional', dhpdf, dstdf))\n",
    "\n",
    "dashdata = get_dashdata(data, ymlpath, write_yml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllayout = build_dashboard(None, **dashdata)\n",
    "output_file(f'{workdir}/04_poisshidim.html')\n",
    "save(fulllayout, title=dashdata['header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The High-Dimensional Poisson Dashboard (Version 1)\n",
    "\n",
    "This was an the earliest attempt at collecting the high-dimensional poisson problem results.\n",
    "\n",
    "The following issues exist with this benchmarking:\n",
    "\n",
    "1. The Poisson problem dimension range is [2, 4, 8, 16, 32, 64].\n",
    "\n",
    "2. The SiLU activation with only two layers were used here.\n",
    "\n",
    "3. An initial condition was applied that was neither effective nor harmful.\n",
    "\n",
    "4. The target regularization weight for bootstrapping was not set properly.\n",
    "\n",
    "5. Three poisson charges were placed stochastically in the unit ball.\n",
    "\n",
    "6. Most bootstrapped trainings diverged due to Number 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrypath = f'../summary/03_poisshidim.h5'\n",
    "get_h5du(smrypath, verbose=True, detailed=False)\n",
    "data = load_h5data(smrypath)\n",
    "hpdf = data['hp']\n",
    "statdf = data['stat']\n",
    "\n",
    "i1 = (hpdf['trg/btstrp'] == True)\n",
    "i2 = (hpdf['srfpts/dblsmpl'] == True)\n",
    "i3 = np.logical_not(np.logical_or(i1.values, i2.values))\n",
    "hpdf_bts = hpdf[i1].reset_index(drop=True)\n",
    "statdf_bts = statdf[i1].reset_index(drop=True)\n",
    "hpdf_ds = hpdf[i2].reset_index(drop=True)\n",
    "statdf_ds = statdf[i2].reset_index(drop=True)\n",
    "hpdf_mse = hpdf[i3].reset_index(drop=True)\n",
    "statdf_mse = statdf[i3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymlpath = f'{workdir}/03_poisshidim.yml'\n",
    "\n",
    "all_dims = sorted(hpdf['dim'].unique().tolist())\n",
    "data = []\n",
    "for dim in all_dims:\n",
    "    didx = (hpdf['dim'] == dim)\n",
    "    dhpdf = hpdf.loc[didx, :].reset_index(drop=True)\n",
    "    dstdf = statdf.loc[didx, :].reset_index(drop=True)\n",
    "    data.append((f'{dim}-Dimensional', dhpdf, dstdf))\n",
    "\n",
    "dashdata = get_dashdata(data, ymlpath, write_yml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllayout = build_dashboard(None, **dashdata)\n",
    "output_file(f'{workdir}/03_poisshidim.html')\n",
    "save(fulllayout, title=dashdata['header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 2-Dimensional Poisson Problem Ablations Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrypath = f'11_plotting/poisson.h5'\n",
    "get_h5du(smrypath, verbose=True, detailed=False)\n",
    "data = load_h5data(smrypath)\n",
    "data_ = hie2deep(data, maxdepth=1)\n",
    "dfd_bts = data_['bts']\n",
    "dfd_mse = data_['mse']\n",
    "dfd_ds = data_['ds']\n",
    "hpdf_mse = dfd_mse['hp']\n",
    "statdf_mse = dfd_mse['stat']\n",
    "hpdf_bts = dfd_bts['hp']\n",
    "statdf_bts = dfd_bts['stat']\n",
    "hpdf_ds = dfd_ds['hp']\n",
    "statdf_ds = dfd_ds['stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymlpath = f'{workdir}/01_poisson.yml'\n",
    "data = [('Standard Training',  hpdf_mse, statdf_mse),\n",
    "        ('Bootstrapping',      hpdf_bts, statdf_bts),\n",
    "        ('Double Sampling',    hpdf_ds,  statdf_ds )]\n",
    "\n",
    "dashdata = get_dashdata(data, ymlpath, write_yml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllayout = build_dashboard(None, **dashdata)\n",
    "output_file(f'{workdir}/01_poisson.html')\n",
    "save(fulllayout, title=dashdata['header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The 1-Dimensional Smoluchowski Problem Ablations Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrypath = f'11_plotting/smoluchowski.h5'\n",
    "get_h5du(smrypath, verbose=True, detailed=False)\n",
    "data = load_h5data(smrypath)\n",
    "data_ = hie2deep(data, maxdepth=1)\n",
    "dfd_bts = data_['bts']\n",
    "dfd_mse = data_['mse']\n",
    "hpdf_mse = dfd_mse['hp']\n",
    "statdf_mse = dfd_mse['stat']\n",
    "hpdf_bts = dfd_bts['hp']\n",
    "statdf_bts = dfd_bts['stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymlpath = f'{workdir}/02_smoluchowski.yml'\n",
    "data = [('Standard Training', hpdf_mse, statdf_mse),\n",
    "        ('Bootstrapping',     hpdf_bts, statdf_bts)]\n",
    "\n",
    "dashdata = get_dashdata(data, ymlpath, write_yml=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulllayout = build_dashboard(None, **dashdata)\n",
    "output_file(f'{workdir}/02_smoluchowski.html')\n",
    "save(fulllayout, title=dashdata['header'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "uhpdf = hpdf.drop_duplicates().copy()\n",
    "uhpdf = drop_unqcols(uhpdf.drop('fpidx', axis=1))\n",
    "uhpdf = uhpdf.reset_index(drop=True)\n",
    "uhpidf = uhpdf.copy().set_index('fpidxgrp')\n",
    "for ii, fpidxs in enumerate(fpgrps):\n",
    "    grphpdf = drop_unqcols(uhpidf.loc[fpidxs].reset_index('fpidxgrp'))\n",
    "    print(f'Group {ii}')\n",
    "    ICD.display(grphpdf)\n",
    "    print('-'*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Feb 24 2021, 21:46:12) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4aec7983bc6059d1b5d440a2253fd0eef7d09b7a26ee33cf7f8716a3ef03c04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
