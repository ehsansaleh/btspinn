{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a53002",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "if importlib.util.find_spec(\"matplotlib_inline\") is not None:\n",
    "    import matplotlib_inline\n",
    "    matplotlib_inline.backend_inline.set_matplotlib_formats('png')\n",
    "else:\n",
    "    from IPython.display import set_matplotlib_formats\n",
    "    set_matplotlib_formats('png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bff7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorboardX, datetime\n",
    "import pandas as pd\n",
    "from scipy.special import gamma\n",
    "from torch import nn\n",
    "from scipy.stats import special_ortho_group\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict as odict\n",
    "from copy import deepcopy\n",
    "from matplotlib.ticker import EngFormatter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "075db014",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figs = False\n",
    "save_figs = False\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "! mkdir -p figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429fa7a",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "Consider the $d$-dimensional space $\\mathbb{R}^{d}$, and the following charge:\n",
    "\n",
    "$$\\rho(x) = \\delta^d(x).$$\n",
    "\n",
    "For $d \\neq 2$ The analytical solution to the system\n",
    "\n",
    "$$\\nabla \\cdot \\vec{E} = \\rho$$\n",
    "\n",
    "$$\\nabla V = \\vec{E}$$\n",
    "\n",
    "can be defined as \n",
    "\n",
    "$$V_{\\vec{x}} = \\frac{\\Gamma(d/2)}{2\\cdot\\pi^{d/2}\\cdot (2-d)} \\|\\vec{x}\\|^{2-d}, $$\n",
    "\n",
    "$$\\vec{E}_{\\vec{x}} = \\frac{\\Gamma(d/2)}{2\\cdot \\pi^{d/2}\\cdot \\|\\vec{x}\\|^{d}} \\vec{x}.$$\n",
    "\n",
    "For $d=2$, $\\vec{E}_{\\vec{x}}$ is the same, but for $V_{\\vec{x}}$ we have\n",
    "\n",
    "$$V_{\\vec{x}} = \\frac{1}{2\\pi} \\ln(\\|\\vec{x}\\|).$$\n",
    "\n",
    "We want to solve this system using the divergence theorem:\n",
    "\n",
    "$$\\iint_{S_{d-1}(V)} \\vec{E}\\cdot \\hat{n}\\text{ d}S = \\iiint_{V_d} \\nabla.\\vec{E}\\text{ d}V.$$\n",
    "\n",
    "Keep in mind that the $d-1$-dimensional surface of a $d$-dimensional shpere with radius $r$ is \n",
    "$$\\iint_{S_{d-1}(V^{\\text{d-Ball}}_{r})} 1\\text{ d}S = \\frac{2\\cdot \\pi^{d/2}}{\\Gamma(d/2)}\\cdot r^{d-1}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8256593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = 'cuda:0'\n",
    "tch_device = torch.device(device_name)\n",
    "tch_dtype = torch.double\n",
    "torch.pi = torch.tensor(np.pi).to(device=tch_device, dtype=tch_dtype)\n",
    "\n",
    "def isscalar(v):\n",
    "    if torch.is_tensor(v):\n",
    "        return v.numel() == 1\n",
    "    else:\n",
    "        return np.isscalar(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8325d2b0",
   "metadata": {},
   "source": [
    "## Defining the Problem and the Analytical Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03cfae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaProblem:\n",
    "    def __init__(self, weights, locations):\n",
    "        # weights          -> np.array -> shape=(N,)\n",
    "        # locations.shape  -> np.array -> shape=(N,d)\n",
    "        self.weights = weights\n",
    "        self.locations = locations\n",
    "        self.n = self.weights.size\n",
    "        self.d = self.locations.shape[1]\n",
    "        assert self.weights.shape   == (self.n,)\n",
    "        assert self.locations.shape == (self.n, self.d)\n",
    "        self.weights_tch = torch.from_numpy(self.weights).to(tch_device, tch_dtype)\n",
    "        self.locations_tch = torch.from_numpy(self.locations).to(tch_device, tch_dtype)\n",
    "    \n",
    "    def integrate_volumes(self, volumes):\n",
    "        # volumes -> dictionary\n",
    "        assert volumes['type'] == 'balls'\n",
    "        centers = volumes['centers']\n",
    "        radii = volumes['radii']\n",
    "        N_v = centers.shape[0]\n",
    "        N_mu, d = self.n, self.d\n",
    "        assert radii.shape == (N_v,)\n",
    "        lib = torch if torch.is_tensor(centers) else np \n",
    "        mu = self.locations_tch if torch.is_tensor(centers) else self.locations\n",
    "        w = self.weights_tch if torch.is_tensor(centers) else self.weights\n",
    "        \n",
    "        c_diff_mu = centers.reshape(N_v, 1, d) - mu.reshape(1, N_mu, d)\n",
    "        assert c_diff_mu.shape == (N_v, N_mu, d)\n",
    "        distl2 = lib.sqrt(lib.square(c_diff_mu).sum(-1))\n",
    "        assert distl2.shape == (N_v, N_mu)\n",
    "        integ = ((distl2 < radii.reshape(N_v, 1)) * w.reshape(1, N_mu)).sum(-1)\n",
    "        assert integ.shape == (N_v,)\n",
    "        return integ\n",
    "    \n",
    "    def potential(self, x):\n",
    "        lib = torch if torch.is_tensor(x) else np \n",
    "        w = self.weights_tch if torch.is_tensor(x) else self.weights\n",
    "        mu = self.locations_tch if torch.is_tensor(x) else self.locations\n",
    "        N_mu, d = self.n, self.d\n",
    "        N_x = x.shape[0]\n",
    "        assert x.shape == (N_x, d)\n",
    "        x_diff_mu = x.reshape(N_x, 1, d) - mu.reshape(1, N_mu, d)\n",
    "        assert x_diff_mu.shape == (N_x, N_mu, d)\n",
    "        x_dists = lib.sqrt(lib.square(x_diff_mu).sum(-1))\n",
    "        assert x_dists.shape == (N_x, N_mu)\n",
    "        if d != 2:\n",
    "            poten1 = (x_dists**(2-d))\n",
    "            assert poten1.shape == (N_x, N_mu)\n",
    "            poten2 = (poten1 * w.reshape(1, N_mu)).sum(-1)\n",
    "            assert poten2.shape == (N_x,)\n",
    "            cst = gamma(d/2) / (2*(lib.pi**(d/2)))\n",
    "            cst = cst / (2-d)\n",
    "            assert isscalar(cst)\n",
    "            poten = cst * poten2\n",
    "            assert poten.shape == (N_x,)\n",
    "        else:\n",
    "            poten1 = lib.log(x_dists)\n",
    "            assert poten1.shape == (N_x, N_mu)\n",
    "            poten2 = (poten1 * w.reshape(1, N_mu)).sum(-1)\n",
    "            assert poten2.shape == (N_x,)\n",
    "            poten = poten2 / (2*lib.pi)\n",
    "            assert poten.shape == (N_x,)\n",
    "        return poten\n",
    "    \n",
    "    def field(self, x):\n",
    "        lib = torch if torch.is_tensor(x) else np \n",
    "        w = self.weights_tch if torch.is_tensor(x) else self.weights\n",
    "        mu = self.locations_tch if torch.is_tensor(x) else self.locations\n",
    "        N_mu, d = self.n, self.d\n",
    "        N_x = x.shape[0]\n",
    "        assert x.shape == (N_x, d)\n",
    "        x_diff_mu = x.reshape(N_x, 1, d) - mu.reshape(1, N_mu, d)\n",
    "        assert x_diff_mu.shape == (N_x, N_mu, d)\n",
    "        x_dists = lib.sqrt(lib.square(x_diff_mu).sum(-1))\n",
    "        assert x_dists.shape == (N_x, N_mu)\n",
    "        poten1 = (x_dists**(-d))\n",
    "        assert poten1.shape == (N_x, N_mu)\n",
    "        poten2 = (poten1 * w.reshape(1, N_mu)).sum(-1)\n",
    "        assert poten2.shape == (N_x,)\n",
    "        cst = gamma(d/2) / (2*(lib.pi**(d/2)))\n",
    "        assert isscalar(cst)\n",
    "        poten = cst * poten2\n",
    "        assert poten.shape == (N_x,)\n",
    "        field = poten.reshape(N_x, 1) * x\n",
    "        assert field.shape == (N_x, d)\n",
    "        return field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb3e68d",
   "metadata": {},
   "source": [
    "## Visualizing the True Potential and Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeee34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_1d = torch.linspace(-1.0, 1.0, 250, requires_grad=True, dtype=tch_dtype, device=tch_device)\n",
    "x2_1d = torch.linspace(-1.0, 1.0, 250, requires_grad=True, dtype=tch_dtype, device=tch_device)\n",
    "x1_msh, x2_msh = torch.meshgrid(x1_1d, x2_1d)\n",
    "x1 = x1_msh.reshape(-1, 1)\n",
    "x2 = x2_msh.reshape(-1, 1)\n",
    "x1_1d_c = x1_1d.reshape(-1, 1)\n",
    "x2_1d_c = x2_1d.reshape(-1, 1)\n",
    "x1_msh_np = x1_msh.detach().cpu().numpy()\n",
    "x2_msh_np = x2_msh.detach().cpu().numpy()\n",
    "x = torch.cat([x1, x2], dim=1)\n",
    "x_np = x.detach().cpu().numpy()\n",
    "x_plt, x_plt_np = x, x_np\n",
    "x1_plt_msh_np, x2_plt_msh_np = x1_msh_np, x2_msh_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525e67f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_plot(x1_msh_np, x2_msh_np, v_msh_np, e_msh_np=None, e_percentile_cap=None, \n",
    "            dpi=72, fig_ax=None, vec_ss=None, cnorm=None, print_colorbar=True,\n",
    "            cmap='RdBu'):\n",
    "    plt.ioff()\n",
    "    if fig_ax is None:\n",
    "        fig = plt.figure(dpi=dpi)\n",
    "        ax = plt.gca()\n",
    "    else:\n",
    "        fig, ax = fig_ax\n",
    "    \n",
    "    v_msh_np_ = v_msh_np - v_msh_np.mean()\n",
    "    \n",
    "    mappable = mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap)\n",
    "    im = ax.pcolormesh(x1_msh_np, x2_msh_np, v_msh_np_, shading='auto', \n",
    "                       norm=cnorm, cmap=cmap, linewidth=0, rasterized=True)\n",
    "    if print_colorbar:\n",
    "        fig.colorbar(mappable if cnorm is not None else im, ax=ax)\n",
    "    \n",
    "    if e_msh_np is not None:\n",
    "        if e_percentile_cap is not None:\n",
    "            e_size = np.sqrt((e_msh_np**2).sum(axis=-1))\n",
    "            e_size_cap = np.percentile(a=e_size, q=e_percentile_cap, axis=None)\n",
    "            cap_coef = np.ones_like(e_size)\n",
    "            cap_coef[e_size > e_size_cap] = e_size_cap / e_size[e_size > e_size_cap]\n",
    "            e_msh_capped = e_msh_np * cap_coef.reshape(*e_msh_np.shape[:-1], 1)\n",
    "        else:\n",
    "            e_msh_capped = e_msh_np\n",
    "        \n",
    "        if vec_ss is None:\n",
    "            x1_msh_np_q, x2_msh_np_q, e_msh_capped_q = x1_msh_np, x2_msh_np, e_msh_capped\n",
    "        else:\n",
    "            assert isinstance(vec_ss, int)\n",
    "            x1_msh_np_q = x1_msh_np[::vec_ss, ::vec_ss]\n",
    "            x2_msh_np_q = x2_msh_np[::vec_ss, ::vec_ss]\n",
    "            e_msh_capped_q = e_msh_capped[::vec_ss, ::vec_ss, :]\n",
    "        ax.quiver(x1_msh_np_q, x2_msh_np_q, e_msh_capped_q[:, :, 0], e_msh_capped_q[:, :, 1])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9385c6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2d_ex1 = DeltaProblem(weights=np.array([1.0]),\n",
    "                         locations=np.array([[ 0.0,  0.0]]))\n",
    "\n",
    "prob2d_ex1 = DeltaProblem(weights=np.array([1.0, 1.0, 1.0]),\n",
    "                         locations=np.array([[ 0.0,  0.0],\n",
    "                                             [-0.5, -0.5],\n",
    "                                             [ 0.5,  0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "748a065f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_ex = prob2d_ex1.potential(x_plt_np)\n",
    "e_ex = prob2d_ex1.field(x_plt_np)\n",
    "\n",
    "fig, ax = do_plot(x1_plt_msh_np, x2_plt_msh_np, \n",
    "                  v_ex.reshape(*x1_plt_msh_np.shape),\n",
    "                  e_ex.reshape(*x1_plt_msh_np.shape, 2),\n",
    "                  e_percentile_cap=90, dpi=36, vec_ss=3)\n",
    "\n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3319be1",
   "metadata": {},
   "source": [
    "### Defining the Volume Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86e5270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BallSampler:\n",
    "    def __init__(self, x_min, x_max, r_min, r_max):\n",
    "        self.np_random = None\n",
    "        self.tch_random = None\n",
    "        self.d = x_min.size\n",
    "        self.x_min = x_min.reshape(1, self.d)\n",
    "        self.x_max = x_max.reshape(1, self.d)\n",
    "        self.r_min = r_min\n",
    "        self.r_max = r_max\n",
    "        self.x_size = (self.x_max - self.x_min)\n",
    "        self.r_size = (self.r_max - self.r_min)\n",
    "        \n",
    "        self.x_min_tch = torch.from_numpy(self.x_min).to(device=tch_device, dtype=tch_dtype)\n",
    "        self.x_max_tch = torch.from_numpy(self.x_max).to(device=tch_device, dtype=tch_dtype)\n",
    "        self.r_min_tch = torch.tensor(self.r_min).to(device=tch_device, dtype=tch_dtype)\n",
    "        self.r_max_tch = torch.tensor(self.r_max).to(device=tch_device, dtype=tch_dtype)\n",
    "        self.x_size_tch = torch.from_numpy(self.x_size).to(device=tch_device, dtype=tch_dtype)\n",
    "        self.r_size_tch = torch.tensor(self.r_size).to(device=tch_device, dtype=tch_dtype)\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        self.tch_random = torch.Generator(device=tch_device)\n",
    "        self.np_random = np.random.RandomState(seed=seed)\n",
    "        tch_seed = self.np_random.randint(0, 0x0fff_ffff_ffff_ffff)\n",
    "        self.tch_random.manual_seed(tch_seed)\n",
    "        return seed\n",
    "    \n",
    "    def __call__(self, n=1, lib='numpy'):\n",
    "        if lib == 'numpy':\n",
    "            radii = self.np_random.uniform(self.r_min, self.r_max, size=(n,))\n",
    "            centers = self.np_random.uniform(0.0, 1.0, size=(n, self.d))\n",
    "            centers = centers * self.x_size + self.x_min\n",
    "        elif lib == 'torch':\n",
    "            radii = torch.empty(n, device=tch_device, dtype=tch_dtype)\n",
    "            radii = radii.uniform_(generator=self.tch_random) * self.r_size_tch + self.r_min_tch\n",
    "            centers = torch.empty(n, self.d, device=tch_device, dtype=tch_dtype)\n",
    "            centers = centers.uniform_(generator=self.tch_random) * self.x_size_tch + self.x_min_tch\n",
    "        else:\n",
    "            raise RuntimeError('Not implemented!')\n",
    "        d = dict()\n",
    "        d['type'] = 'balls'\n",
    "        d['centers'] = centers\n",
    "        d['radii'] = radii\n",
    "        return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e1605",
   "metadata": {},
   "source": [
    "### Visualizing the Sampler and Integrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9a1d8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob2d_ex2 = DeltaProblem(weights=np.array([1.0, 1.0, 1.0]),\n",
    "                          locations=np.array([[ 0.0,  0.0],\n",
    "                                              [-0.5, -0.5],\n",
    "                                              [ 0.5,  0.5]]))\n",
    "\n",
    "volsampler_2d = BallSampler(x_min=np.array([-1.0, -1.0]), x_max=np.array([1.0, 1.0]), r_min=0.1, r_max=1.5)\n",
    "volsampler_2d.seed(12345)\n",
    "\n",
    "vols = volsampler_2d(n=10, lib='torch')\n",
    "integs = prob2d_ex2.integrate_volumes(vols)\n",
    "for key, val in vols.items():\n",
    "    if torch.is_tensor(val):\n",
    "        vols[key] = val.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b827a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=36)\n",
    "ax = plt.gca()\n",
    "\n",
    "max_integ = prob2d_ex2.weights[prob2d_ex2.weights > 0].sum()\n",
    "min_integ = prob2d_ex2.weights[prob2d_ex2.weights < 0].sum()\n",
    "cmap = mpl.cm.get_cmap('RdBu')\n",
    "cnorm = mpl.colors.Normalize(vmin=min_integ, vmax=max_integ)\n",
    "\n",
    "ax.scatter(prob2d_ex2.locations[:,0], prob2d_ex2.locations[:,1], marker='*', color='black', s=150)\n",
    "for center, radius, integ in zip(vols['centers'], vols['radii'], integs):\n",
    "    circle = plt.Circle(center, radius, fill=False, \n",
    "                        color=cmap(1.0-cnorm(integ.item())))\n",
    "    ax.add_patch(circle)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12b6294",
   "metadata": {},
   "source": [
    "### Sphere Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d890c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SphereSampler:\n",
    "    def __init__(self):\n",
    "        self.np_random = None\n",
    "        self.tch_random = None\n",
    "    \n",
    "    def seed(self, seed=None):\n",
    "        self.tch_random = torch.Generator(device=tch_device)\n",
    "        self.np_random = np.random.RandomState(seed=seed)\n",
    "        tch_seed = self.np_random.randint(0, 0x0fff_ffff_ffff_ffff)\n",
    "        self.tch_random.manual_seed(tch_seed)\n",
    "        return seed\n",
    "    \n",
    "    def np_exlinspace(self, start, end, n):\n",
    "        assert n >= 1\n",
    "        a = np.linspace(start, end, n, endpoint=False) \n",
    "        b = a + 0.5 * (end - a[-1])\n",
    "        return b\n",
    "    \n",
    "    def tch_exlinspace(self, start, end, n):\n",
    "        assert n >= 1\n",
    "        a = torch.linspace(start, end, n+1, device=tch_device, dtype=tch_dtype)[:-1] \n",
    "        b = a + 0.5 * (end - a[-1])\n",
    "        return b\n",
    "    \n",
    "    def __call__(self, volumes, n, do_detspacing=True):\n",
    "        # volumes -> dictionary\n",
    "        assert volumes['type'] == 'balls'\n",
    "        centers = volumes['centers']\n",
    "        radii = volumes['radii']\n",
    "        N_v, d = centers.shape\n",
    "        assert centers.shape == (N_v, d)\n",
    "        assert radii.shape == (N_v,)\n",
    "        use_np = not torch.is_tensor(centers)\n",
    "        exlinspace = self.np_exlinspace if use_np else self.tch_exlinspace\n",
    "        meshgrid = np.meshgrid if use_np else torch.meshgrid\n",
    "        sin = np.sin if use_np else torch.sin\n",
    "        cos = np.cos if use_np else torch.cos\n",
    "        matmul = np.matmul if use_np else torch.matmul\n",
    "        \n",
    "        if do_detspacing and (d == 2):\n",
    "            theta = exlinspace(0.0, 2*np.pi, n)\n",
    "            assert theta.shape == (n,)\n",
    "            theta_2d = theta.reshape(n, 1)\n",
    "            x_tilde_2d_list = [cos(theta_2d), sin(theta_2d)]\n",
    "            if use_np:\n",
    "                x_tilde_2d = np.concatenate(x_tilde_2d_list, axis=1)\n",
    "            else:\n",
    "                x_tilde_2d = torch.cat(x_tilde_2d_list, dim=1)\n",
    "            assert x_tilde_2d.shape == (n ,d)\n",
    "            x_tilde = x_tilde_2d.reshape(1, n, d)\n",
    "            assert x_tilde.shape == (1, n ,d)\n",
    "        elif do_detspacing and (d == 3):\n",
    "            n_sqrt = int(np.sqrt(n))\n",
    "            assert n == n_sqrt * n_sqrt, 'Need n to be int-square for now!'\n",
    "            theta_1d = exlinspace(0.0, 2*np.pi, n_sqrt)\n",
    "            unit_unif = exlinspace(0.0, 1.0, n_sqrt)\n",
    "            if use_np:\n",
    "                phi_1d = np.arccos(1-2*unit_unif)\n",
    "            else:\n",
    "                phi_1d = torch.arccos(1-2*unit_unif)\n",
    "            theta_msh, phi_msh = meshgrid(theta_1d, phi_1d)\n",
    "            assert theta_msh.shape == (n_sqrt, n_sqrt)\n",
    "            assert phi_msh.shape == (n_sqrt, n_sqrt)\n",
    "            theta_2d, phi_2d = theta_msh.reshape(n, 1), phi_msh.reshape(n, 1)\n",
    "            assert theta_2d.shape == (n, 1)\n",
    "            assert phi_2d.shape == (n, 1)\n",
    "            x_tilde_lst = [sin(phi_2d) * cos(theta), sin(phi_2d) * sin(theta), cos(phi_2d)]\n",
    "            if use_np:\n",
    "                x_tilde_2d = np.concatenate(x_tilde_lst, axis=1)\n",
    "            else:\n",
    "                x_tilde_2d = torch.cat(x_tilde_lst, dim=1)\n",
    "            assert x_tilde_2d.shape == (n ,d)\n",
    "            x_tilde = x_tilde_2d.reshape(1, n, d)\n",
    "            assert x_tilde.shape == (1, n ,d)\n",
    "        elif (not do_detspacing) and use_np:\n",
    "            x_tilde_unnorm = self.np_random.randn(N_v, n, d)\n",
    "            x_tilde_l2 = np.sqrt(torch.square(x_tilde_unnorm).sum(axis=-1))\n",
    "            x_tilde = x_tilde_unnorm / x_tilde_l2.reshape(N_v, n, 1)\n",
    "            assert x_tilde.shape == (N_v, n ,d)\n",
    "        elif (not do_detspacing) and (not use_np):\n",
    "            x_tilde_unnorm = torch.empty(N_v, n, d, device=tch_device, dtype=tch_dtype)\n",
    "            x_tilde_unnorm = x_tilde_unnorm.normal_(generator=self.tch_random)\n",
    "            x_tilde_l2 = torch.sqrt(torch.square(x_tilde_unnorm).sum(dim=-1))\n",
    "            x_tilde = x_tilde_unnorm / x_tilde_l2.reshape(N_v, n, 1)\n",
    "            assert x_tilde.shape == (N_v, n ,d)\n",
    "        else:\n",
    "            raise RuntimeError('Not implemented yet!')\n",
    "            \n",
    "        rot_mats_np = special_ortho_group.rvs(dim=d, size=N_v, random_state=self.np_random)\n",
    "        if use_np:\n",
    "            rot_mats = rot_mats_np\n",
    "        else:\n",
    "            rot_mats = torch.from_numpy(rot_mats_np).to(device=tch_device, dtype=tch_dtype)\n",
    "        assert rot_mats.shape == (N_v, d, d)\n",
    "        \n",
    "        x_tilde_rot = matmul(x_tilde, rot_mats)\n",
    "        assert x_tilde_rot.shape == (N_v, n, d)\n",
    "        \n",
    "        points = x_tilde_rot * radii.reshape(N_v, 1, 1) + centers.reshape(N_v, 1, d)\n",
    "        assert points.shape == (N_v, n, d)\n",
    "        \n",
    "        if use_np:\n",
    "            x_tilde_bc = np.broadcast_to(x_tilde, (N_v, n, d))\n",
    "        else:\n",
    "            x_tilde_bc = x_tilde.expand(N_v, n, d)\n",
    "        rot_x_tilde = matmul(x_tilde_bc, rot_mats)\n",
    "        assert rot_x_tilde.shape == (N_v, n, d)\n",
    "        \n",
    "        cst = (2*(np.pi**(d/2))) / gamma(d/2)\n",
    "        csts = cst * (radii**(d-1))\n",
    "        assert csts.shape == (N_v,)\n",
    "        \n",
    "        ret_dict = dict(points=points, normals=rot_x_tilde, areas=csts)\n",
    "        return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "412467c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 100, 2), (10, 100, 2))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob2d_ex3 = DeltaProblem(weights=np.array([1.0, 1.0, 1.0]),\n",
    "                          locations=np.array([[ 0.0,  0.0],\n",
    "                                              [-0.5, -0.5],\n",
    "                                              [ 0.5,  0.5]]))\n",
    "\n",
    "volsampler_2d = BallSampler(x_min=np.array([-1.0, -1.0]), x_max=np.array([1.0, 1.0]), r_min=0.1, r_max=1.5)\n",
    "volsampler_2d.seed(12345)\n",
    "\n",
    "sphsampler_2d = SphereSampler()\n",
    "sphsampler_2d.seed(12345)\n",
    "\n",
    "vols = volsampler_2d(n=10, lib='torch')\n",
    "sphsamps2d = sphsampler_2d(vols, 100, do_detspacing=True)\n",
    "points = sphsamps2d['points']\n",
    "surfacenorms = sphsamps2d['normals']\n",
    "if torch.is_tensor(points):\n",
    "    points = points.detach().cpu().numpy()\n",
    "if torch.is_tensor(surfacenorms):\n",
    "    surfacenorms = surfacenorms.detach().cpu().numpy()\n",
    "points.shape, surfacenorms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff733b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=36)\n",
    "ax = plt.gca()\n",
    "\n",
    "max_integ = prob2d_ex2.weights[prob2d_ex3.weights > 0].sum()\n",
    "min_integ = prob2d_ex2.weights[prob2d_ex3.weights < 0].sum()\n",
    "cmap = mpl.cm.get_cmap('RdBu')\n",
    "cnorm = mpl.colors.Normalize(vmin=min_integ, vmax=max_integ)\n",
    "\n",
    "ax.scatter(prob2d_ex3.locations[:,0], prob2d_ex3.locations[:,1], marker='*', color='black', s=150)\n",
    "for pnts, srfnrms, center, radius, integ in zip(points, surfacenorms, vols['centers'], vols['radii'], integs):\n",
    "    ax.scatter(pnts[:,0], pnts[:,1], marker='o', color=cmap(1.0-cnorm(integ.item())), s=1)\n",
    "    ax.quiver(pnts[:,0], pnts[:,1], srfnrms[:, 0], srfnrms[:, 1], width=0.002)\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76fe19",
   "metadata": {},
   "source": [
    "### Defining the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9e3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the problem\n",
    "d = 2\n",
    "problem = DeltaProblem(weights=np.array([1.0, 1.0, 1.0]),\n",
    "                       locations=np.array([[ 0.0,  0.0],\n",
    "                                           [-0.5, -0.5],\n",
    "                                           [ 0.5,  0.5]]))\n",
    "\n",
    "volsampler = BallSampler(x_min=np.array([-1.0, -1.0]), x_max=np.array([1.0, 1.0]), r_min=0.1, r_max=1.5)\n",
    "sphsampler = SphereSampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef0a21",
   "metadata": {},
   "source": [
    "### Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a2dad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ffnn(nn.Module):\n",
    "    \"\"\"basic FF network for approximating functions\"\"\"\n",
    "    def __init__(self, inp_width=2, nn_width=10, num_hidden=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer_first = nn.Linear(inp_width, nn_width).to(device=tch_device, dtype=tch_dtype)\n",
    "        \n",
    "        layers = []\n",
    "        for _ in range(num_hidden):\n",
    "            layers.append(nn.Linear(nn_width, nn_width).to(device=tch_device, dtype=tch_dtype))\n",
    "        self.layer_hidden = nn.ModuleList(layers)\n",
    "        \n",
    "        self.layer_last = nn.Linear(nn_width, 1).to(device=tch_device, dtype=tch_dtype)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        activation = nn.SiLU()\n",
    "        u = activation(self.layer_first(x))\n",
    "        for hidden in self.layer_hidden:\n",
    "            u = activation(hidden(u))\n",
    "        u = self.layer_last(u)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e53ac7",
   "metadata": {},
   "source": [
    "### Heatmap with MSE Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db7159a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_width, nn_hidden = 64, 2\n",
    "model = ffnn(d, nn_width, nn_hidden)\n",
    "\n",
    "cmap = 'RdBu'\n",
    "\n",
    "cnorm = mpl.colors.Normalize(vmin=-0.75, vmax=0.3, clip=False)\n",
    "cnorm = None\n",
    "\n",
    "ema_gamma = 0.999\n",
    "\n",
    "def ema(x_np):\n",
    "    x = x_np.tolist()\n",
    "    y = np.zeros_like(x_np)\n",
    "    lasty = y[0] = x[0]\n",
    "    for i in range(1, y.size):\n",
    "        y[i] = lasty = lasty * ema_gamma + (1.0-ema_gamma) * x[i]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142c9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowvardir = f'01_poisson/01_lowvar_mse_*'\n",
    "highvardir = f'01_poisson/02_highvar_mse_*'\n",
    "lowvarckpts = f'{lowvardir}/checkpoints.pt'\n",
    "highvarckpts = f'{highvardir}/checkpoints.pt'\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6.5, 1.9), dpi=72)\n",
    "cmappable = mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap)\n",
    "\n",
    "v_true = problem.potential(x_plt_np)\n",
    "e_true = problem.field(x_plt_np)\n",
    "showvecs = False\n",
    "\n",
    "fig, ax = do_plot(x1_plt_msh_np, x2_plt_msh_np, \n",
    "                  v_true.reshape(*x1_plt_msh_np.shape),\n",
    "                  e_true.reshape(*x1_plt_msh_np.shape, 2) if showvecs else None, \n",
    "                  e_percentile_cap=90, fig_ax=(fig, axes[0]), cnorm=cnorm,\n",
    "                  vec_ss=2, print_colorbar=False)\n",
    "ax.set_title('Ground Truth')\n",
    "\n",
    "loopvars = [(lowvarckpts, axes[1], 'Low Var. Training'), \n",
    "            (highvarckpts, axes[2], 'High Var. Training')]\n",
    "for ckptglobpath, ax, ax_title in loopvars:\n",
    "    ckptspath = glob.glob(ckptglobpath)[0]\n",
    "    ckptweights = torch.load(ckptspath)\n",
    "\n",
    "    ckptiters = sorted(ckptweights.keys())\n",
    "    mdlsdcpu = ckptweights[max(ckptiters)]\n",
    "    mdlsd = {key:val.to(device=tch_device) for key, val in mdlsdcpu.items()}\n",
    "    model.load_state_dict(mdlsd)\n",
    "\n",
    "    points_plt = nn.Parameter(x_plt.unsqueeze(0))\n",
    "    v_pred = model(points_plt)\n",
    "    e_pred, = torch.autograd.grad(v_pred.sum(), [points_plt], grad_outputs=None, retain_graph=False,\n",
    "                                  create_graph=False, only_inputs=True, allow_unused=False)\n",
    "    v_pred_np = v_pred.squeeze().detach().cpu().numpy()\n",
    "    e_pred_np = e_pred.squeeze().detach().cpu().numpy()\n",
    "    \n",
    "    fig, ax = do_plot(x1_plt_msh_np, x2_plt_msh_np, \n",
    "                      v_pred_np.reshape(*x1_plt_msh_np.shape),\n",
    "                      e_pred_np.reshape(*x1_plt_msh_np.shape, 2) if showvecs else None, \n",
    "                      e_percentile_cap=90, fig_ax=(fig, ax), cnorm=cnorm,\n",
    "                      print_colorbar=False, vec_ss=2)\n",
    "    ax.set_title(ax_title)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_yticks([], minor=True)\n",
    "\n",
    "if cnorm is not None:\n",
    "    fig.colorbar(cmappable, ax=axes)\n",
    "\n",
    "if save_figs:\n",
    "    fig.savefig('./02_poisson/msegt_heatmap.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "    \n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28556563",
   "metadata": {},
   "source": [
    "### MSE Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "370b6cc7",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "lowvarcsvpath = glob.glob(f'{lowvardir}/progress.csv')[0]\n",
    "highvarcsvpath = glob.glob(f'{highvardir}/progress.csv')[0]\n",
    "dflowvar = pd.read_csv(lowvarcsvpath)\n",
    "dfhighvar = pd.read_csv(highvarcsvpath)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(5.1, 2.1), dpi=72, sharex=True, sharey=True)\n",
    "    \n",
    "ax = axes[0]\n",
    "ax.plot(dflowvar['epoch'], ema(dflowvar['loss']), color='blue', lw=2, label='Low Var')\n",
    "ax.plot(dfhighvar['epoch'], ema(dfhighvar['loss']), color='red', lw=2, label='high Var')\n",
    "\n",
    "ax.set_xticks(np.linspace(0, 200_000, 5))\n",
    "engfmt = EngFormatter(sep='')\n",
    "ax.xaxis.set_major_formatter(engfmt)\n",
    "ax.set_xlabel(f'Epoch')\n",
    "\n",
    "ax.set_yscale('log', base=10)\n",
    "ax.set_yticks([0.01, 0.03, 0.1, 0.3, 1, 3])\n",
    "ax.set_ylim(0.005, 5)\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "ax.set_ylabel(f'Training Loss')\n",
    "\n",
    "ax.annotate('N=2', xy=(100_000, 0.25), xytext=(140_000, 1.0),\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=-120\"))\n",
    "\n",
    "ax.annotate('N=100', xy=(100_000, 0.035), xytext=(140_000, 0.008),\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=120\"))\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(dflowvar['epoch'], ema(dflowvar['npvm']), color='blue', lw=2, label='Low Var')\n",
    "ax.plot(dfhighvar['epoch'], ema(dfhighvar['npvm']), color='red', lw=2, label='high Var')\n",
    "\n",
    "ax.set_xticks(np.linspace(0, 200_000, 5))\n",
    "engfmt = EngFormatter(sep='')\n",
    "ax.xaxis.set_major_formatter(engfmt)\n",
    "ax.set_xlabel(f'Epoch')\n",
    "ax.set_ylabel(f'Integration Variance')\n",
    "\n",
    "ax.annotate('N=100', xy=(100_000, 1.6), xytext=(140_000, 2.5),\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=-150\"))\n",
    "\n",
    "ax.annotate('N=2', xy=(100_000, 0.26), xytext=(140_000, 0.1),\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=140\"))\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "if save_figs:\n",
    "    fig.savefig('./02_poisson/loss_vs_epoch_mse.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d6363",
   "metadata": {},
   "source": [
    "### Heatmap with the Bootstrapped Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcb19388",
   "metadata": {},
   "outputs": [],
   "source": [
    "showvecs = False\n",
    "loopvars = [('03_highvar_bstrap_*', 2000, '_diverged'),\n",
    "            ('04_highvar_bstrap_*', 199000, '_lowq'),\n",
    "            ('06_highvar_bstrap_*', 183000, '')]\n",
    "\n",
    "for dirname, ckptiter, postfix in loopvars: \n",
    "    mainckpts = f'01_poisson/{dirname}/checkpoints.pt'\n",
    "    trgtckpts = f'01_poisson/{dirname}/checkpoints_trg.pt'\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(4.1, 1.9), dpi=72)\n",
    "    cmappable = mpl.cm.ScalarMappable(norm=cnorm, cmap=cmap)\n",
    "\n",
    "\n",
    "    loopvars2 = [(mainckpts, axes[0], 'Main Model'), \n",
    "                (trgtckpts, axes[1], 'Target Model')]\n",
    "    for i, (ckptglobpath, ax, ax_title) in enumerate(loopvars2):\n",
    "        ckptspath = glob.glob(ckptglobpath)[0]\n",
    "        ckptweights = torch.load(ckptspath)\n",
    "\n",
    "        ckptiters = sorted(ckptweights.keys())\n",
    "        mdlsdcpu = ckptweights[max(ckptiters) if ckptiter == 'max' else ckptiter]\n",
    "        mdlsd = {key:val.to(device=tch_device) for key, val in mdlsdcpu.items()}\n",
    "        model.load_state_dict(mdlsd)\n",
    "\n",
    "        points_plt = nn.Parameter(x_plt.unsqueeze(0))\n",
    "        v_pred = model(points_plt)\n",
    "        e_pred, = torch.autograd.grad(v_pred.sum(), [points_plt], grad_outputs=None, retain_graph=False,\n",
    "                                      create_graph=False, only_inputs=True, allow_unused=False)\n",
    "        v_pred_np = v_pred.squeeze().detach().cpu().numpy()\n",
    "        e_pred_np = e_pred.squeeze().detach().cpu().numpy()\n",
    "\n",
    "        fig, ax = do_plot(x1_plt_msh_np, x2_plt_msh_np, \n",
    "                          v_pred_np.reshape(*x1_plt_msh_np.shape),\n",
    "                          e_pred_np.reshape(*x1_plt_msh_np.shape, 2) if showvecs else None, \n",
    "                          e_percentile_cap=90, fig_ax=(fig, ax), cnorm=cnorm,\n",
    "                          print_colorbar=False, vec_ss=5)\n",
    "        ax.set_title(ax_title)\n",
    "        if i > 0:\n",
    "            ax.set_yticks([])\n",
    "            ax.set_yticks([], minor=True)\n",
    "\n",
    "    if cnorm is not None:\n",
    "        fig.colorbar(cmappable, ax=axes)\n",
    "\n",
    "    if save_figs:\n",
    "        fig.savefig(f'./02_poisson/bstrap_heatmap{postfix}.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69a4d57",
   "metadata": {},
   "source": [
    "### MSE Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "720d11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, ckptiter, postfix in loopvars: \n",
    "    maincsvpath = glob.glob(f'01_poisson/{dirname}/progress.csv')[0]\n",
    "    dfmain = pd.read_csv(maincsvpath)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(2.5, 2.6), dpi=72, sharex=True, sharey=True)\n",
    "\n",
    "    ema_gamma = 0.999\n",
    "\n",
    "    ax = axes\n",
    "    epochs, losses = dfmain['epoch'], ema(dfmain['loss'])\n",
    "    if postfix in ('', '_lowq'):\n",
    "        epochs, losses = epochs[::1000], losses[::1000]\n",
    "    ax.plot(epochs, losses, color='green', lw=2, label='Bootstrapped')\n",
    "    if postfix in ('', '_lowq'):\n",
    "        ax.plot(dfhighvar['epoch'][::1000], ema(dfhighvar['loss'])[::1000], \n",
    "                color='red', lw=1., ls='--', label='high Var')\n",
    "        ax.plot(dflowvar['epoch'][::1000], ema(dflowvar['loss'])[::1000], \n",
    "                color='blue', lw=1., ls='--', label='Low Var')\n",
    "\n",
    "    if postfix in ('_diverged',):\n",
    "        ax.set_xticks(np.linspace(0, 10_000, 6))\n",
    "    else:\n",
    "        ax.set_xticks(np.linspace(0, 200_000, 5))\n",
    "    engfmt = EngFormatter(sep='')\n",
    "    ax.xaxis.set_major_formatter(engfmt)\n",
    "    ax.set_xlabel(f'Epoch')\n",
    "\n",
    "    ax.set_yscale('log', base=10)\n",
    "    if postfix not in ('_diverged',):\n",
    "        ax.set_yticks([0.01, 0.03, 0.1, 0.3, 1, 3])\n",
    "        ax.set_ylim(0.005, 5)\n",
    "        ax.yaxis.set_major_formatter(mpl.ticker.ScalarFormatter())\n",
    "    ax.set_ylabel(f'Training Loss')\n",
    "\n",
    "    if postfix == '':\n",
    "        ax.annotate('N=2', xy=(40_000, 1.3), xytext=(80_000, 0.5),\n",
    "                    arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=150\"))\n",
    "    elif postfix == '_lowq':\n",
    "        ax.annotate('N=2', xy=(40_000, 0.5), xytext=(80_000, 1.2),\n",
    "                arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"angle3,angleA=0,angleB=-90\"))\n",
    "\n",
    "    fig.set_tight_layout(True)\n",
    "    \n",
    "    if save_figs:\n",
    "        fig.savefig(f'./02_poisson/loss_vs_epoch_bstrap{postfix}.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "    \n",
    "    if show_figs:\n",
    "        plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9d3502",
   "metadata": {},
   "source": [
    "### Can we compute the analytical solution's surface integration variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db8b21eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spheres = 1000\n",
    "n_points = 10000\n",
    "\n",
    "volsampler.seed(12345)\n",
    "sphsampler.seed(12345)\n",
    "\n",
    "# Sampling the volumes\n",
    "volsamps = volsampler(n=n_spheres, lib='torch')\n",
    "\n",
    "# Sampling the points from the spheres\n",
    "sphsamps = sphsampler(volsamps, n_points, do_detspacing=True)\n",
    "points = nn.Parameter(sphsamps['points'])\n",
    "surfacenorms = sphsamps['normals']\n",
    "areas = sphsamps['areas']\n",
    "assert points.shape == (n_spheres, n_points, d)\n",
    "assert surfacenorms.shape == (n_spheres, n_points, d)\n",
    "assert areas.shape == (n_spheres,)\n",
    "\n",
    "points_e_true = problem.field(points.reshape(n_spheres * n_points, d)).reshape(n_spheres, n_points, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e058ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(6, 2.2), dpi=72)\n",
    "\n",
    "field_sizes = points_e_true.norm(dim=-1).reshape(-1)\n",
    "assert field_sizes.shape == (n_spheres*n_points,)\n",
    "q = torch.linspace(0, 1, 1001, dtype=tch_dtype, device=tch_device)\n",
    "quants = field_sizes.quantile(q)\n",
    "\n",
    "keepidxs = torch.linspace(0, n_spheres*n_points-1, 10000)\n",
    "keepidxs = keepidxs.round().to(dtype=torch.long, device=tch_device)\n",
    "field_sizes_sorted = torch.sort(field_sizes).values\n",
    "field_sizes_ss = field_sizes_sorted.index_select(dim=0, index=keepidxs)\n",
    "\n",
    "ax = axes[0]\n",
    "ax.hist(field_sizes_ss.log10().detach().cpu().numpy(), bins=100)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel(r'$\\log_{10}||\\vec{E}||_2$')\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(q.detach().cpu().numpy(), quants.detach().cpu().numpy(), color='blue', lw=2)\n",
    "ax.set_xlabel('Percentile')\n",
    "ax.set_ylabel(r'$\\log_{10}||\\vec{E}||_2$')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "if save_figs:\n",
    "    fig.savefig('./02_poisson/count_vs_esize_true.pdf', dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "if show_figs:\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d22225",
   "metadata": {},
   "source": [
    "As you can see above, the singularities in the true vector fields show up with a non-negligible probability, and push the surface normal product variance to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d098ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
